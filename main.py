# main.py
# DG å®ç›˜æ£€æµ‹ + ç«‹å³å†å²æ›¿è¡¥ï¼ˆWayback / å…¬å…± APIï¼‰-> Telegram
# IMPORTANT:
#  - ä¿æŒæ–‡ä»¶åä¸º main.py ï¼ˆä¸è¦æ”¹åï¼‰
#  - åœ¨è¿è¡Œç¯å¢ƒä¸­è®¾ç½® TG_BOT_TOKEN ä¸ TG_CHAT_IDï¼ˆæˆ–åœ¨ GitHub Secrets æ³¨å…¥ï¼‰
#  - å¯é€‰ï¼šè®¾ç½® FORCE_TEST_SEND=1 æ¥å¼ºåˆ¶å‘é€ä¸€æ¬¡æµ‹è¯• Telegramï¼ˆéƒ¨ç½²éªŒè¯æ—¶ç”¨ï¼‰
#
# æ”¹è¿›è¦ç‚¹ï¼ˆæœ¬ç‰ˆæœ¬ï¼‰ï¼š
#  1) å¦‚æœæ— æ³•è¿›å…¥å®ç›˜æˆ–ç‚¹æ•°ä¸è¶³ -> ç«‹å³å‘é€ Telegram: "è¿›å…¥å¤±è´¥ï¼Œå¼€å§‹æ›¿è¡¥"ï¼ˆè®©ä½ çŸ¥é“è„šæœ¬åœ¨å·¥ä½œï¼‰
#  2) æ›¿è¡¥è‹¥æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„äº‹ä»¶ -> ç«‹å³å‘é€æ”¾æ°´/ä¸­ç­‰èƒœç‡æé†’ï¼ˆæ ¼å¼å« emojiã€å¼€å§‹/ä¼°è®¡ç»“æŸ/å‰©ä½™åˆ†é’Ÿï¼‰
#  3) è‹¥æ›¿è¡¥æ— æ³•æ‰¾åˆ°è¶³å¤Ÿå†å² -> ç«‹å³å‘é€ Telegram: "æ›¿è¡¥æ— è¶³å¤Ÿå†å²"ï¼ˆé¿å…ä½ ç™½ç­‰ï¼‰
#  4) åœ¨æ¯ä¸ªå…³é”®æ­¥éª¤å†™å…¥ last_screenshot.pngã€last_summary.jsonã€state.jsonï¼Œä¾¿äºè°ƒè¯•
#
# è¿è¡Œæç¤ºï¼š
#  - æœ¬è„šæœ¬ä¾èµ– playwrightã€Pillowã€opencv-python-headlessã€numpyã€requests
#  - å¦‚æœåœ¨ GitHub Actions ä¸­ï¼Œç¡®ä¿ workflow æœ‰è¶³å¤Ÿ timeoutï¼ˆWayback æ¸²æŸ“å¯èƒ½è€—æ—¶ï¼‰
#  - è‹¥ç”¨æœ¬åœ°è¿è¡Œï¼Œè¯·å…ˆ install requirements å¹¶ playwright install chromium
# ------------------------------------------------------------------------------

import os, sys, json, time, random, traceback
from datetime import datetime, timedelta, timezone
from io import BytesIO
import requests
from PIL import Image
import numpy as np
import cv2
from playwright.sync_api import sync_playwright, TimeoutError as PWTimeout

# ---------- é…ç½®ï¼ˆå¯ç”¨ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰ ----------
DG_LINKS = ["https://dg18.co/wap/", "https://dg18.co/"]
TG_TOKEN_ENV = "TG_BOT_TOKEN"
TG_CHAT_ENV = "TG_CHAT_ID"

# é˜ˆå€¼ä¸å‚æ•°
MIN_POINTS_FOR_REAL = int(os.environ.get("MIN_POINTS_FOR_REAL", "40"))
DILATE_KERNEL_SIZE = int(os.environ.get("DILATE_KERNEL_SIZE", "40"))
MIN_BOARDS_FOR_PAW = int(os.environ.get("MIN_BOARDS_FOR_PAW", "3"))
HISTORY_LOOKBACK_DAYS = int(os.environ.get("HISTORY_LOOKBACK_DAYS", "28"))
MIN_HISTORY_EVENTS_FOR_PRED = int(os.environ.get("MIN_HISTORY_EVENTS_FOR_PRED", "3"))
PRED_BUCKET_MINUTES = int(os.environ.get("PRED_BUCKET_MINUTES", "15"))
PRED_LEAD_MINUTES = int(os.environ.get("PRED_LEAD_MINUTES", "10"))
WAYBACK_MAX_SNAPSHOTS = int(os.environ.get("WAYBACK_MAX_SNAPSHOTS","40"))
WAYBACK_RATE_SLEEP = float(os.environ.get("WAYBACK_RATE_SLEEP","1.2"))

FORCE_TEST_SEND = os.environ.get("FORCE_TEST_SEND", "0") in ("1","true","True")

STATE_FILE = "state.json"
SUMMARY_FILE = "last_summary.json"
LAST_SCREENSHOT = "last_screenshot.png"

TZ = timezone(timedelta(hours=8))  # Malaysia UTC+8

# ---------- å·¥å…· ----------
def now_tz(): return datetime.now(TZ)
def nowstr(): return now_tz().strftime("%Y-%m-%d %H:%M:%S")
def log(s): print(f"[{nowstr()}] {s}", flush=True)

# ---------- Telegram ----------
def send_telegram(text, max_retries=3):
    token = os.environ.get(TG_TOKEN_ENV, "").strip()
    chat = os.environ.get(TG_CHAT_ENV, "").strip()
    if not token or not chat:
        log("Telegram æœªé…ç½®ï¼ˆTG_BOT_TOKEN æˆ– TG_CHAT_ID ç¼ºå¤±ï¼‰")
        return False, "no_token"
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    data = {"chat_id": chat, "text": text}
    for i in range(max_retries):
        try:
            r = requests.post(url, data=data, timeout=12)
            j = r.json()
            if j.get("ok"):
                log("Telegram å‘é€æˆåŠŸ")
                return True, j
            else:
                log(f"Telegram è¿”å›é ok: {j}")
                time.sleep(1 + random.random())
        except Exception as e:
            log(f"Telegram å‘é€å¼‚å¸¸ (å°è¯• {i+1}): {e}")
            time.sleep(1 + random.random())
    return False, "failed"

# ---------- state --------------
def load_state():
    if not os.path.exists(STATE_FILE):
        return {"active":False,"kind":None,"start_time":None,"last_seen":None,"history":[]}
    try:
        with open(STATE_FILE,"r",encoding="utf-8") as f:
            return json.load(f)
    except:
        return {"active":False,"kind":None,"start_time":None,"last_seen":None,"history":[]}

def save_state(s):
    with open(STATE_FILE,"w",encoding="utf-8") as f:
        json.dump(s,f,ensure_ascii=False,indent=2)

# ---------- image helpers ---------------
def pil_from_bytes(b): return Image.open(BytesIO(b)).convert("RGB")
def cv_from_pil(p): return cv2.cvtColor(np.array(p), cv2.COLOR_RGB2BGR)

def detect_color_points(bgr):
    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)
    lower1,upper1 = np.array([0,90,60]), np.array([10,255,255])
    lower2,upper2 = np.array([160,90,60]), np.array([179,255,255])
    mask_r = cv2.inRange(hsv, lower1, upper1) | cv2.inRange(hsv, lower2, upper2)
    lowerb,upperb = np.array([85,60,40]), np.array([140,255,255])
    mask_b = cv2.inRange(hsv, lowerb, upperb)
    kernel = np.ones((3,3), np.uint8)
    mask_r = cv2.morphologyEx(mask_r, cv2.MORPH_OPEN, kernel, iterations=1)
    mask_b = cv2.morphologyEx(mask_b, cv2.MORPH_OPEN, kernel, iterations=1)
    points=[]
    for mask,label in [(mask_r,'B'),(mask_b,'P')]:
        cnts,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for cnt in cnts:
            area = cv2.contourArea(cnt)
            if area < 8: continue
            M = cv2.moments(cnt)
            if M.get("m00",0)==0: continue
            cx = int(M["m10"]/M["m00"]); cy = int(M["m01"]/M["m00"])
            points.append((cx,cy,label))
    return points, mask_r, mask_b

def cluster_points_to_boards(points, img_shape):
    h,w = img_shape[:2]
    mask = np.zeros((h,w), dtype=np.uint8)
    for x,y,_ in points:
        if 0<=x<w and 0<=y<h: mask[y,x]=255
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (DILATE_KERNEL_SIZE,DILATE_KERNEL_SIZE))
    big = cv2.dilate(mask, kernel, iterations=1)
    num,labels,stats,_ = cv2.connectedComponentsWithStats(big, connectivity=8)
    rects=[]
    for i in range(1,num):
        x,y,w_,h_ = stats[i,cv2.CC_STAT_LEFT], stats[i,cv2.CC_STAT_TOP], stats[i,cv2.CC_STAT_WIDTH], stats[i,cv2.CC_STAT_HEIGHT]
        if w_<60 or h_<40: continue
        pad=8
        x0=max(0,x-pad); y0=max(0,y-pad); x1=min(w-1,x+w_+pad); y1=min(h-1,y+h_+pad)
        rects.append((x0,y0,x1-x0,y1-y0))
    if not rects:
        cols=max(3,w//300); rows=max(2,h//200)
        cw=w//cols; ch=h//rows
        for r in range(rows):
            for c in range(cols):
                rects.append((c*cw, r*ch, cw, ch))
    return rects

def analyze_board(bgr, rect):
    x,y,w,h = rect
    crop = bgr[y:y+h, x:x+w]
    pts,_,_ = detect_color_points(crop)
    pts_local = [(px,py,c) for (px,py,c) in pts]
    if not pts_local:
        return {"total":0,"maxRun":0,"category":"empty","columns":[],"runs":[]}
    xs = [p[0] for p in pts_local]
    idx_sorted = sorted(range(len(xs)), key=lambda i: xs[i])
    col_groups=[]
    for idx in idx_sorted:
        xv = xs[idx]; placed=False
        for g in col_groups:
            gxs=[pts_local[i][0] for i in g]
            if abs(np.mean(gxs)-xv) <= max(10, w//40):
                g.append(idx); placed=True; break
        if not placed:
            col_groups.append([idx])
    columns=[]
    for g in col_groups:
        col_pts = sorted([pts_local[i] for i in g], key=lambda t:t[1])
        columns.append([p[2] for p in col_pts])
    flattened=[]
    maxlen = max((len(c) for c in columns), default=0)
    for r in range(maxlen):
        for col in columns:
            if r < len(col): flattened.append(col[r])
    runs=[]
    if flattened:
        cur={'color':flattened[0],'len':1}
        for k in range(1,len(flattened)):
            if flattened[k]==cur['color']: cur['len']+=1
            else:
                runs.append(cur); cur={'color':flattened[k],'len':1}
        runs.append(cur)
    maxRun = max((r['len'] for r in runs), default=0)
    cat='other'
    if maxRun>=10: cat='super_long'
    elif maxRun>=8: cat='long'
    elif maxRun>=4: cat='longish'
    elif maxRun==1: cat='single'
    return {"total":len(flattened),"maxRun":maxRun,"category":cat,"columns":columns,"runs":runs}

# ---------- classification ----------
def classify_overall(board_infos):
    longCount = sum(1 for b in board_infos if b['category'] in ('long','super_long'))
    superCount = sum(1 for b in board_infos if b['category']=='super_long')
    def board_has_3consec_multicolumn(columns):
        col_runlens=[]
        for col in columns:
            if not col: col_runlens.append(0); continue
            ccur=col[0]; clen=1; maxc=1
            for t in col[1:]:
                if t==ccur: clen+=1
                else:
                    if clen>maxc: maxc=clen
                    ccur=t; clen=1
            if clen>maxc: maxc=clen
            col_runlens.append(maxc)
        for i in range(len(col_runlens)-2):
            if col_runlens[i]>=4 and col_runlens[i+1]>=4 and col_runlens[i+2]>=4:
                return True
        return False
    boards_with_multicol = sum(1 for b in board_infos if board_has_3consec_multicolumn(b['columns']))
    boards_with_long = sum(1 for b in board_infos if b['maxRun'] >= 8)
    if longCount >= MIN_BOARDS_FOR_PAW:
        return "æ”¾æ°´æ—¶æ®µï¼ˆæé«˜èƒœç‡ï¼‰", longCount, superCount
    if boards_with_multicol >= 3 and boards_with_long >= 2:
        return "ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Šï¼‰", boards_with_long, sum(1 for b in board_infos if b['category']=='super_long')
    totals = [b['total'] for b in board_infos]
    if board_infos and sum(1 for t in totals if t < 6) >= len(board_infos)*0.6:
        return "èƒœç‡è°ƒä½ / æ”¶å‰²æ—¶æ®µ", sum(1 for b in board_infos if b['maxRun']>=8), sum(1 for b in board_infos if b['category']=='super_long')
    return "èƒœç‡ä¸­ç­‰ï¼ˆå¹³å°æ”¶å‰²ä¸­ç­‰æ—¶æ®µï¼‰", sum(1 for b in board_infos if b['maxRun']>=8), sum(1 for b in board_infos if b['category']=='super_long')

# ---------- Playwright helpers ----------
def apply_stealth(page):
    page.add_init_script("""
    Object.defineProperty(navigator, 'webdriver', {get: () => false});
    Object.defineProperty(navigator, 'languages', {get: () => ['en-US','en']});
    Object.defineProperty(navigator, 'plugins', {get: () => [1,2,3,4]});
    window.chrome = { runtime: {} };
    """)

def human_like_drag(page, start_x, start_y, end_x, end_y, steps=30):
    page.mouse.move(start_x, start_y)
    page.mouse.down()
    for i in range(1, steps+1):
        nx = start_x + (end_x - start_x) * (i/steps) + random.uniform(-2,2)
        ny = start_y + (end_y - start_y) * (i/steps) + random.uniform(-1,1)
        page.mouse.move(nx, ny, steps=1)
        time.sleep(random.uniform(0.01, 0.03))
    page.mouse.up()

def try_solve_slider(page):
    try:
        selectors = ["input[type=range]","div[role=slider]","div[class*=slider]","div[class*=captcha]","div[class*=slide]"]
        for sel in selectors:
            try:
                els = page.query_selector_all(sel)
                if els and len(els)>0:
                    box = els[0].bounding_box()
                    if box:
                        x0 = box['x']+2; y0 = box['y'] + box['height']/2
                        x1 = box['x'] + box['width'] - 6
                        human_like_drag(page, x0, y0, x1, y0, steps=30)
                        time.sleep(0.8)
                        return True
            except:
                continue
        # æˆªå›¾å›¾åƒè¾…åŠ©æ‰¾ slider
        ss = page.screenshot(full_page=True)
        img = pil_from_bytes(ss); bgr = cv_from_pil(img)
        H,W = bgr.shape[:2]
        region = bgr[int(H*0.25):int(H*0.75), int(W*0.05):int(W*0.95)]
        gray = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)
        _,th = cv2.threshold(gray,200,255,cv2.THRESH_BINARY)
        cnts,_ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        best=None; best_area=0
        for cnt in cnts:
            bx,by,bw,bh = cv2.boundingRect(cnt); area=bw*bh
            if area>best_area and bw>40 and bw>3*bh:
                best=(bx,by,bw,bh); best_area=area
        if best:
            bx,by,bw,bh = best
            px=int(W*0.05)+bx; py=int(H*0.25)+by
            sx = px+6; sy = py + bh//2; ex = px + bw - 6
            human_like_drag(page, sx, sy, ex, sy, steps=30)
            time.sleep(1.0)
            return True
    except Exception as e:
        log(f"try_solve_slider å¼‚å¸¸: {e}")
    return False

def capture_dg_page(attempts=3):
    with sync_playwright() as p:
        uas = [
            "Mozilla/5.0 (Linux; Android 12; Pixel 5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Mobile Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        ]
        viewports = [(390,844),(1280,900)]
        for attempt in range(attempts):
            ua = random.choice(uas); vw,vh = random.choice(viewports)
            browser = p.chromium.launch(headless=True, args=["--no-sandbox"])
            context = browser.new_context(user_agent=ua, viewport={"width":vw,"height":vh}, locale="en-US")
            page = context.new_page(); apply_stealth(page)
            time.sleep(random.uniform(0.3,0.9))
            for url in DG_LINKS:
                try:
                    log(f"æ‰“å¼€ {url} ï¼ˆå°è¯• {attempt+1}ï¼‰")
                    page.goto(url, timeout=30000)
                    time.sleep(0.8 + random.random())
                    clicked=False
                    for txt in ["Free","å…è´¹è¯•ç©","å…è´¹","Play Free","è¯•ç©","Free Play","å…è´¹ä½“éªŒ"]:
                        try:
                            loc = page.locator(f"text={txt}")
                            if loc.count()>0:
                                loc.first.click(timeout=3000); clicked=True; log(f"ç‚¹å‡»æ–‡æœ¬ {txt}"); break
                        except:
                            continue
                    if not clicked:
                        try:
                            els = page.query_selector_all("a,button")
                            for i in range(min(80,len(els))):
                                try:
                                    t = els[i].inner_text().strip().lower()
                                    if "free" in t or "è¯•ç©" in t or "å…è´¹" in t:
                                        els[i].click(timeout=2000); clicked=True; log("ç‚¹å‡»å€™é€‰ a/button"); break
                                except:
                                    continue
                        except:
                            pass
                    time.sleep(0.6 + random.random())
                    # å°è¯•æ»‘å—å¤šæ¬¡
                    for s in range(6):
                        got = try_solve_slider(page)
                        log(f"slider å°è¯• {s+1} -> {got}")
                        if got: break
                        else:
                            try:
                                page.mouse.wheel(0,300); time.sleep(0.5)
                            except:
                                pass
                    # æ£€æµ‹ç‚¹æ•°
                    for chk in range(8):
                        ss = page.screenshot(full_page=True)
                        try:
                            with open(LAST_SCREENSHOT,"wb") as f: f.write(ss)
                        except:
                            pass
                        img = pil_from_bytes(ss); bgr = cv_from_pil(img)
                        pts,_,_ = detect_color_points(bgr)
                        log(f"æ£€æŸ¥ {chk+1}: ç‚¹æ•° {len(pts)}")
                        if len(pts) >= MIN_POINTS_FOR_REAL:
                            log("è¿›å…¥å®ç›˜ï¼ˆç‚¹æ•°é˜ˆå€¼è¾¾æˆï¼‰")
                            context.close(); browser.close()
                            return ss
                        time.sleep(1.0 + random.random() * 0.6)
                except PWTimeout as e:
                    log(f"é¡µé¢æ‰“å¼€è¶…æ—¶: {e}")
                except Exception as e:
                    log(f"ä¸é¡µé¢äº¤äº’å¼‚å¸¸: {e}")
            try:
                context.close()
            except: pass
            try: browser.close()
            except: pass
            time.sleep(1.8 + random.random())
        log("æœªèƒ½è¿›å…¥å®ç›˜ï¼ˆå¤šæ¬¡å°è¯•å¤±è´¥ï¼‰")
        return None

# ---------- Wayback / history helpers ----------
def get_wayback_snapshots(url, from_date=None, to_date=None, limit=40):
    base = "http://web.archive.org/cdx/search/cdx"
    params = {"url":url, "output":"json", "filter":"statuscode:200", "limit":str(limit)}
    if from_date: params["from"]=from_date
    if to_date: params["to"]=to_date
    try:
        r = requests.get(base, params=params, timeout=12)
        if r.status_code!=200:
            log(f"Wayback CDX è¿”å› {r.status_code}")
            return []
        j = r.json()
        if not j or len(j)<2: return []
        rows = j[1:]
        tss = [row[1] for row in rows if len(row)>1]
        return tss
    except Exception as e:
        log(f"Wayback CDX å¼‚å¸¸: {e}")
        return []

def fetch_wayback_snapshot_and_screenshot(snapshot_ts, target_url):
    snap = f"https://web.archive.org/web/{snapshot_ts}/{target_url}"
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True, args=["--no-sandbox"])
            context = browser.new_context(viewport={"width":1280,"height":900})
            page = context.new_page()
            page.goto(snap, timeout=30000)
            time.sleep(1.8)
            ss = page.screenshot(full_page=True)
            context.close(); browser.close()
            return ss
    except Exception as e:
        log(f"Wayback æ¸²æŸ“å¤±è´¥ {snapshot_ts}: {e}")
        return None

def try_fetch_public_history():
    tried=[]
    for base in DG_LINKS:
        for path in ["/api/history","/history","/api/v1/history","/game/history","/api/records"]:
            url = base.rstrip("/") + path
            tried.append(url)
            try:
                r = requests.get(url, timeout=8)
                if r.status_code==200:
                    try:
                        return r.json()
                    except:
                        continue
            except:
                continue
    log(f"å°è¯•å…¬å…±å†å²æ¥å£: {tried}")
    return None

def predict_from_history(state):
    hist = state.get("history",[]) or []
    now = now_tz()
    cutoff = now - timedelta(days=HISTORY_LOOKBACK_DAYS)
    recent=[]
    for ev in hist:
        try:
            st = datetime.fromisoformat(ev["start_time"])
            st = st.astimezone(TZ) if st.tzinfo else st.replace(tzinfo=timezone.utc).astimezone(TZ)
            if st >= cutoff: recent.append({"kind":ev.get("kind"), "start":st, "duration":ev.get("duration_minutes",0)})
        except:
            continue
    if len(recent) < MIN_HISTORY_EVENTS_FOR_PRED:
        return None
    buckets={}
    for ev in recent:
        weekday = ev["start"].weekday(); hour = ev["start"].hour
        bmin = (ev["start"].minute // PRED_BUCKET_MINUTES) * PRED_BUCKET_MINUTES
        key=(ev["kind"], weekday, hour, bmin)
        if key not in buckets: buckets[key]={"count":0,"durations":[]}
        buckets[key]["count"]+=1; buckets[key]["durations"].append(ev["duration"])
    candidates=[]
    for k,v in buckets.items():
        if v["count"] >= MIN_HISTORY_EVENTS_FOR_PRED:
            avg = round(sum(v["durations"])/len(v["durations"])) if v["durations"] else 10
            candidates.append({"key":k,"count":v["count"],"avg_duration":avg})
    if not candidates: return None
    candidates.sort(key=lambda x:x["count"], reverse=True)
    best = candidates[0]
    kind, weekday, hour, bmin = best["key"]
    now = now_tz()
    days_ahead = (weekday - now.weekday()) % 7
    predicted_start = (now + timedelta(days=days_ahead)).replace(hour=hour, minute=bmin, second=0, microsecond=0)
    if predicted_start < now - timedelta(minutes=1):
        predicted_start += timedelta(days=7)
    predicted_end = predicted_start + timedelta(minutes=best["avg_duration"])
    return {"kind":kind, "predicted_start":predicted_start, "predicted_end":predicted_end, "avg_duration":best["avg_duration"], "count":best["count"]}

# ---------- main logic ----------
def main():
    log("=== DG monitor run start ===")
    # optional forced test send (use for debug only; set FORCE_TEST_SEND=1 env to test)
    if FORCE_TEST_SEND:
        send_telegram("ğŸ”§ [DG Monitor] æµ‹è¯•æ¶ˆæ¯ï¼šFORCE_TEST_SEND=1ï¼ŒTelegram é€šçŸ¥æ­£å¸¸ã€‚")
        log("å·²å‘é€å¼ºåˆ¶æµ‹è¯• Telegramï¼ˆFORCE_TEST_SEND=1ï¼‰ã€‚é€€å‡ºä»¥é¿å…é‡å¤å‘é€ã€‚")
        return

    state = load_state()
    screenshot = None
    try:
        screenshot = capture_dg_page()
    except Exception as e:
        log(f"capture_dg_page å¼‚å¸¸: {e}\n{traceback.format_exc()}")

    # å¦‚æœå¾—åˆ°äº†æˆªå›¾ï¼Œåšå®æ—¶æ£€æµ‹
    if screenshot:
        with open(LAST_SCREENSHOT,"wb") as f: f.write(screenshot)
        img = Image.open(LAST_SCREENSHOT).convert("RGB")
        bgr = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        pts,_,_ = detect_color_points(bgr)
        log(f"å®æ—¶æ£€æµ‹ç‚¹æ•°: {len(pts)}")
        if len(pts) < MIN_POINTS_FOR_REAL:
            # ç‚¹æ•°ä¸è¶³ -> ç«‹å³é€šçŸ¥å¹¶è¿›å…¥æ›¿è¡¥
            send_telegram("âš ï¸ [DG Monitor] å·²è¿›å…¥é¡µé¢ä½†ç‚¹æ•°ä¸è¶³ï¼Œå‡†å¤‡æ‰§è¡Œå†å²æ›¿è¡¥åˆ¤å®šï¼ˆé©¬ä¸Šé€šçŸ¥ç»“æœï¼‰ã€‚")
            fallback_with_history(state)
            return
        rects = cluster_points_to_boards(pts, bgr.shape)
        boards=[]
        for r in rects: boards.append(analyze_board(bgr, r))
        overall, longCount, superCount = classify_overall(boards)
        log(f"å®æ—¶åˆ¤å®š: {overall} (é•¿é¾™/è¶…: {longCount}/{superCount})")
        nowiso = now_tz().isoformat()
        was_active = state.get("active", False)
        is_active_now = overall in ("æ”¾æ°´æ—¶æ®µï¼ˆæé«˜èƒœç‡ï¼‰","ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Šï¼‰")
        if is_active_now and not was_active:
            state={"active":True,"kind":overall,"start_time":nowiso,"last_seen":nowiso,"history":state.get("history",[])}
            save_state(state)
            durations = [h.get("duration_minutes",0) for h in state.get("history",[]) if h.get("duration_minutes",0)>0]
            est_min = round(sum(durations)/len(durations)) if durations else 10
            est_end = (now_tz() + timedelta(minutes=est_min)).strftime("%Y-%m-%d %H:%M:%S")
            msg = f"ğŸ”” [DGæé†’ - å³æ™‚] {overall} é–‹å§‹\næ™‚é–“: {nowiso}\né•¿é¾™/è¶…é¾™ æ¡Œæ•¸: {longCount} (è¶…é¾™:{superCount})\nä¼°è¨ˆçµæŸ: {est_end}ï¼ˆç´„ {est_min} åˆ†é˜ï¼‰"
            send_telegram(msg)
            save_state(state)
        elif is_active_now and was_active:
            state["last_seen"]=nowiso; state["kind"]=overall; save_state(state); log("äº‹ä»¶æŒçºŒä¸­")
        elif not is_active_now and was_active:
            start_time = datetime.fromisoformat(state.get("start_time"))
            end_time = now_tz()
            dur = round((end_time - start_time).total_seconds() / 60.0)
            hist = state.get("history",[]); hist.append({"kind":state.get("kind"), "start_time": state.get("start_time"), "end_time": end_time.isoformat(), "duration_minutes": dur})
            state={"active":False,"kind":None,"start_time":None,"last_seen":None,"history": hist[-2000:]}
            save_state(state)
            msg = f"âœ… [DGæé†’] {state.get('kind')} å·²çµæŸ\né–‹å§‹: {state.get('start_time')}\nçµæŸ: {end_time.isoformat()}\nå¯¦éš›æŒçºŒ: {dur} åˆ†é˜"
            send_telegram(msg)
            log("å·²ç™¼çµæŸé€šçŸ¥")
        else:
            log("éæ”¾æ°´/ä¸­ä¸Šæ™‚æ®µï¼Œä¸ç™¼é€æé†’ï¼ˆä½†æœ¬æ¬¡å¯¦ç›¤æª¢æ¸¬æˆåŠŸï¼‰")
        # å†™ summary æ–¹ä¾¿è°ƒè¯•
        try:
            with open(SUMMARY_FILE,"w",encoding="utf-8") as f:
                json.dump({"ts":now_tz().isoformat(),"overall":overall,"longCount":longCount,"superCount":superCount}, f, ensure_ascii=False, indent=2)
        except:
            pass
        return
    else:
        # æœªæˆåŠŸè¿›å…¥å®ç›˜ -> ç«‹åˆ»é€šçŸ¥å¹¶è¿›å…¥å†å²æ›¿è¡¥
        send_telegram("âš ï¸ [DG Monitor] æœªèƒ½è¿›å…¥ DG å®ç›˜ï¼Œç«‹å³å¯åŠ¨å†å²æ›¿è¡¥ï¼ˆWayback/å…¬å…± APIï¼‰å¹¶é©¬ä¸Šé€šçŸ¥ç»“æœã€‚")
        fallback_with_history(state)
        return

def fallback_with_history(state):
    log("å¼€å§‹å†å²æ›¿è¡¥æµç¨‹ï¼ˆWayback + å…¬å…± APIï¼‰")
    # 1) å°è¯•å…¬å…±å†å² API
    try:
        api_hist = try_fetch_public_history()
    except Exception as e:
        api_hist = None
        log(f"try_fetch_public_history å¼‚å¸¸: {e}")
    if api_hist:
        # å½’ä¸€åŒ–å¹¶åˆå…¥ state.history
        norm=[]
        if isinstance(api_hist, list):
            for rec in api_hist:
                st = rec.get("start_time") or rec.get("ts") or rec.get("time")
                end = rec.get("end_time") or rec.get("end")
                dur = rec.get("duration_minutes") or rec.get("duration")
                if st:
                    norm.append({"kind": rec.get("kind","æ”¾æ°´"), "start_time": st, "end_time": end, "duration_minutes": dur or 0})
        elif isinstance(api_hist, dict):
            for key in ("events","history","records"):
                if key in api_hist and isinstance(api_hist[key], list):
                    for rec in api_hist[key]:
                        st = rec.get("start_time") or rec.get("ts") or rec.get("time")
                        end = rec.get("end_time") or rec.get("end")
                        dur = rec.get("duration_minutes") or rec.get("duration")
                        if st:
                            norm.append({"kind": rec.get("kind","æ”¾æ°´"), "start_time": st, "end_time": end, "duration_minutes": dur or 0})
                    break
        if norm:
            hist = state.get("history",[]) or []
            hist.extend(norm)
            state["history"] = hist[-2000:]
            save_state(state)
            log(f"ä»å…¬å…± API å¯¼å…¥ {len(norm)} æ¡å†å²")
    # 2) è¯„ä¼°ç°æœ‰å†å²æ˜¯å¦è¶³å¤Ÿ
    recent_count = 0
    for h in state.get("history",[]) or []:
        try:
            st = datetime.fromisoformat(h["start_time"]); st = st.astimezone(TZ) if st.tzinfo else st.replace(tzinfo=timezone.utc).astimezone(TZ)
            if st >= now_tz() - timedelta(days=HISTORY_LOOKBACK_DAYS): recent_count += 1
        except:
            continue
    if recent_count < MIN_HISTORY_EVENTS_FOR_PRED:
        log("å†å²è®°å½•ä¸è¶³ -> å°è¯• Wayback å¿«ç…§æ”¶é›†")
        from_date = (now_tz() - timedelta(days=HISTORY_LOOKBACK_DAYS)).strftime("%Y%m%d")
        to_date = now_tz().strftime("%Y%m%d")
        collected = 0
        for base in DG_LINKS:
            tss = get_wayback_snapshots(base, from_date=from_date, to_date=to_date, limit=WAYBACK_MAX_SNAPSHOTS)
            if not tss:
                log(f"Wayback æœªå‘ç° {base} çš„å¿«ç…§ï¼ˆè¿‡å» {HISTORY_LOOKBACK_DAYS} å¤©ï¼‰")
                continue
            for ts in tss[:WAYBACK_MAX_SNAPSHOTS]:
                time.sleep(WAYBACK_RATE_SLEEP)
                ss = fetch_wayback_snapshot_and_screenshot(ts, base)
                if not ss: continue
                try:
                    with open(LAST_SCREENSHOT,"wb") as f: f.write(ss)
                except: pass
                try:
                    img = Image.open(LAST_SCREENSHOT).convert("RGB")
                    bgr = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
                except:
                    continue
                pts,_,_ = detect_color_points(bgr)
                if len(pts) < MIN_POINTS_FOR_REAL: continue
                rects = cluster_points_to_boards(pts, bgr.shape)
                boards=[]
                for r in rects: boards.append(analyze_board(bgr, r))
                overall, longCount, superCount = classify_overall(boards)
                if overall in ("æ”¾æ°´æ—¶æ®µï¼ˆæé«˜èƒœç‡ï¼‰","ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Šï¼‰"):
                    try:
                        ev_time = datetime.strptime(ts[:14], "%Y%m%d%H%M%S").replace(tzinfo=timezone.utc).astimezone(TZ)
                    except:
                        ev_time = now_tz()
                    rec = {"kind": overall, "start_time": ev_time.isoformat(), "end_time": (ev_time + timedelta(minutes=10)).isoformat(), "duration_minutes": 10, "source":"wayback_snapshot"}
                    hist = state.get("history",[]) or []
                    hist.append(rec)
                    state["history"] = hist[-2000:]
                    save_state(state)
                    collected += 1
                    log(f"Wayback å‘ç°äº‹ä»¶ {overall} @ {ts}ï¼Œå·²è®°å½•")
        log(f"Wayback æ”¶é›†ç»“æŸï¼Œå…±æ”¶é›† {collected} æ¡äº‹ä»¶")
    else:
        log(f"å·²æœ‰è¶³å¤Ÿæœ€è¿‘å†å² (count={recent_count})ï¼Œè·³è¿‡ Wayback æ”¶é›†")

    # 3) æ£€æŸ¥å†å²æ˜¯å¦è¶³å¤Ÿå¹¶åšé¢„æµ‹/æé†’ï¼ˆç«‹å³è§¦å‘ï¼‰
    hist_now = 0
    for h in state.get("history",[]) or []:
        try:
            st = datetime.fromisoformat(h["start_time"]); st = st.astimezone(TZ) if st.tzinfo else st.replace(tzinfo=timezone.utc).astimezone(TZ)
            if st >= now_tz() - timedelta(days=HISTORY_LOOKBACK_DAYS): hist_now += 1
        except:
            continue
    log(f"å¤„ç†åæœ€è¿‘å†å²æ•°é‡: {hist_now}")
    if hist_now < MIN_HISTORY_EVENTS_FOR_PRED:
        send_telegram("âš ï¸ [DG Monitor] æ›¿è¡¥æ‰§è¡Œå®Œæ¯•ï¼Œä½†æ— æ³•æ‰¾åˆ°è¶³å¤Ÿçš„æœ€è¿‘ 4 å‘¨å†å²æ•°æ®æ¥åšå¯é é¢„æµ‹ã€‚è„šæœ¬å°†ç»§ç»­æ”¶é›†å†å²å¹¶åœ¨æœªæ¥è§¦å‘ã€‚")
        save_state(state)
        return

    pred = predict_from_history(state)
    if not pred:
        send_telegram("âš ï¸ [DG Monitor] æ›¿è¡¥æ‰§è¡Œå®Œæ¯•ï¼Œä½†æœªèƒ½ä»å†å²ä¸­æ‰¾å‡ºç¨³å®šæ”¾æ°´ / ä¸­ä¸Š æ¨¡å¼ï¼ˆæ— å¯é é¢„æµ‹ï¼‰ã€‚")
        save_state(state); return

    ps = pred["predicted_start"]; pe = pred["predicted_end"]
    now = now_tz(); lead = timedelta(minutes=PRED_LEAD_MINUTES)
    if (ps - lead) <= now <= pe:
        remaining = max(0, int((pe - now).total_seconds()//60))
        msg = f"ğŸ”” [DGæ›¿è£œ - æ­·å²å…¨å¸‚å ´] æ ¹æ“šæœ€è¿‘ {HISTORY_LOOKBACK_DAYS} å¤©çš„å…¨å¸‚å ´æ­·å²æ¨¡å¼åµæ¸¬åˆ°å¯èƒ½çš„ã€{pred['kind']}ã€\né æ¸¬é–‹å§‹: {ps.strftime('%Y-%m-%d %H:%M:%S')}\nä¼°è¨ˆçµæŸ: {pe.strftime('%Y-%m-%d %H:%M:%S')}ï¼ˆç´„ {pred['avg_duration']} åˆ†é˜ï¼‰\nç›®å‰å‰©é¤˜: ç´„ {remaining} åˆ†é˜\nâ€» æ›¿è£œä¾†æº: Wayback / å…¬å…±æ­·å²è³‡æ–™ï¼ˆéå³æ™‚å¯¦ç›¤ï¼‰ã€‚"
        # é¿å…é‡å¤
        hist = state.get("history",[]) or []
        duplicate=False
        for h in hist[-80:]:
            try:
                if h.get("kind")==pred["kind"]:
                    tm = datetime.fromisoformat(h["start_time"]).astimezone(TZ)
                    if abs((tm - ps).total_seconds()) < 60*5:
                        duplicate=True; break
            except:
                continue
        if not duplicate:
            send_telegram(msg)
            hist.append({"kind":pred["kind"], "start_time": ps.isoformat(), "end_time": pe.isoformat(), "duration_minutes": pred["avg_duration"], "source":"historical_predict"})
            state["history"] = hist[-2000:]; save_state(state)
            log("å·²å‘é€æ›¿è¡¥é¢„æµ‹æé†’å¹¶è®°å½•")
        else:
            log("æ£€æµ‹åˆ°è¿‘ä¼¼å†å²è®°å½•ï¼Œè·³è¿‡é‡å¤æé†’")
    else:
        log(f"é¢„æµ‹ä¸‹ä¸€æ¬¡ {pred['kind']} å¼€å§‹äº {ps.strftime('%Y-%m-%d %H:%M:%S')}ï¼Œä¸åœ¨æé†’çª—å£å†…")
    save_state(state)
    return

# ---------- entry ----------
if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        log(f"Unhandled exception: {e}\n{traceback.format_exc()}")
        sys.exit(1)
