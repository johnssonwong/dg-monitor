# -*- coding: utf-8 -*-
"""
DG å®ç›˜æ£€æµ‹ä¸»è„šæœ¬ï¼ˆé’ˆå¯¹ GitHub Actions / Playwrightï¼‰
åŠŸèƒ½ï¼š
- ä½¿ç”¨ Playwright è‡ªåŠ¨æ‰“å¼€ DG é“¾æ¥ (dg18.co/wap æˆ– dg18.co)
- ç‚¹å‡» "Free" / "å…è´¹è¯•ç©" å¹¶å°è¯•é€šè¿‡å¼¹çª—/æ»‘å—å®‰å…¨æ¡ï¼ˆè‡ªåŠ¨æ‹–åŠ¨ï¼‰
- æˆªå›¾ DG å®ç›˜é¡µé¢å¹¶ç”¨ OpenCV åˆ†ææ¯ä¸ªæ¡Œé¢ï¼šè¯†åˆ«çº¢/è“ç ã€è®¡ç®—è¿é•¿ã€åˆ¤æ–­å¤šè¿/é•¿é¾™/è¶…é•¿é¾™ã€ä»¥åŠåˆ¤æ–­æ•´ä½“æ—¶æ®µ
- æŒ‰è§„åˆ™åˆ¤æ–­ï¼šæ”¾æ°´æ—¶æ®µ / ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Šï¼‰ / èƒœç‡ä¸­ç­‰ / èƒœç‡è°ƒä½ï¼ˆæ”¶å‰²ï¼‰
- ä»…åœ¨æ”¾æ°´ æˆ– ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Šï¼‰ è§¦å‘ Telegram æé†’ï¼ˆå¼€å§‹é€šçŸ¥å¸¦ emojiã€ä¼°ç®—ç»“æŸæ—¶é—´ï¼‰ï¼›å½“è¯¥å±€åŠ¿ç»“æŸæ—¶å†å‘ç»“æŸé€šçŸ¥ï¼ˆå¹¶å†™å…¥å†å²ä»¥ä¾¿ä¼°ç®—å°†æ¥æŒç»­æ—¶é—´ï¼‰
- å°†çŠ¶æ€å­˜å‚¨åœ¨ state.jsonï¼ˆå¹¶ç”± workflow commit å› repoï¼‰ï¼Œä»¥ä½œä¸ºå†å²æ•°æ®ä¸å»é‡/å†·å´ä¾æ®
æ³¨æ„ï¼šè¯·åœ¨ GitHub Secrets ä¸­æ”¾å…¥ TG_BOT_TOKEN ä¸ TG_CHAT_ID
"""

import os, time, json, math, random
from datetime import datetime, timedelta, timezone
from pathlib import Path
import requests
import numpy as np
from io import BytesIO
from PIL import Image
import cv2

# Playwright
from playwright.sync_api import sync_playwright

# sklearn kmeans for fallback clustering
from sklearn.cluster import KMeans

# ------------------ é…ç½®ï¼ˆå¯é€šè¿‡ env / secrets è¦†ç›–ï¼‰ ------------------
TG_BOT_TOKEN = os.environ.get("TG_BOT_TOKEN", "").strip()
TG_CHAT_ID  = os.environ.get("TG_CHAT_ID", "").strip()

DG_LINKS = [
    "https://dg18.co/wap/",
    "https://dg18.co/"
]

# åˆ¤å®šå‚æ•°ï¼ˆå¿…è¦æ—¶å¯åœ¨ workflow ç¯å¢ƒå˜é‡ä¸­è¦†ç›–ï¼‰
MIN_BOARDS_FOR_PAW = int(os.environ.get("MIN_BOARDS_FOR_PAW", "3"))   # æ”¾æ°´è‡³å°‘æ»¡è¶³æ¡Œæ•°ï¼ˆâ‰¥3ï¼‰
MID_LONG_REQ = int(os.environ.get("MID_LONG_REQ", "2"))              # ä¸­ç­‰èƒœç‡éœ€è¦ >=2 å¼ é•¿é¾™/è¶…é•¿é¾™
COOLDOWN_MINUTES = int(os.environ.get("COOLDOWN_MINUTES", "10"))     # åœ¨äº‹ä»¶å¼€å§‹åå°†è¿›å…¥å†·å´ï¼Œé¿å…é‡å¤å¼€å§‹æé†’

STATE_FILE = "state.json"
LAST_SUMMARY = "last_run_summary.json"

# é©¬æ¥è¥¿äºšæ—¶åŒº
TZ = timezone(timedelta(hours=8))

# ------------------ logging ------------------
def log(msg):
    print(f"[{datetime.now(TZ).strftime('%Y-%m-%d %H:%M:%S')}] {msg}", flush=True)

# ------------------ Telegram ------------------
def send_telegram(text):
    if not TG_BOT_TOKEN or not TG_CHAT_ID:
        log("Telegram é…ç½®ç¼ºå¤±ï¼Œæ— æ³•å‘é€æ¶ˆæ¯ã€‚")
        return False
    url = f"https://api.telegram.org/bot{TG_BOT_TOKEN}/sendMessage"
    payload = {"chat_id": TG_CHAT_ID, "text": text, "parse_mode": "HTML"}
    try:
        r = requests.post(url, data=payload, timeout=20)
        j = r.json()
        if j.get("ok"):
            log("Telegram: å·²å‘é€é€šçŸ¥ã€‚")
            return True
        else:
            log(f"Telegram API è¿”å›é”™è¯¯: {j}")
            return False
    except Exception as e:
        log(f"å‘é€ Telegram æ—¶å¼‚å¸¸: {e}")
        return False

# ------------------ state ------------------
def load_state():
    if not Path(STATE_FILE).exists():
        s = {"active": False, "kind": None, "start_time": None, "last_seen": None, "history": []}
        return s
    return json.loads(Path(STATE_FILE).read_text(encoding="utf-8"))

def save_state(state):
    Path(STATE_FILE).write_text(json.dumps(state, ensure_ascii=False, indent=2), encoding="utf-8")

# ------------------ å›¾åƒå¤„ç†: æ£€æµ‹çº¢/è“åœ†ç‚¹ ------------------
def pil_from_bytes(data):
    return Image.open(BytesIO(data)).convert("RGB")

def cv_from_pil(pil):
    return cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)

def detect_points(bgr):
    """
    æ›´ç¨³å¥çš„ HSV é˜ˆå€¼æ£€æµ‹çº¢/è“åœ†ç‚¹ã€‚è¿”å› points list: (x,y,label) label 'B' (red åº„) or 'P' (blue é—²)
    """
    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)
    # red range (two ranges)
    lower1 = np.array([0, 100, 80]); upper1 = np.array([10, 255, 255])
    lower2 = np.array([160,100,80]); upper2 = np.array([179,255,255])
    mask_r = cv2.inRange(hsv, lower1, upper1) | cv2.inRange(hsv, lower2, upper2)
    # blue
    lowerb = np.array([90, 60, 50]); upperb = np.array([140, 255, 255])
    mask_b = cv2.inRange(hsv, lowerb, upperb)

    # morphology to reduce noise
    k = np.ones((3,3), np.uint8)
    mask_r = cv2.morphologyEx(mask_r, cv2.MORPH_OPEN, k, iterations=1)
    mask_b = cv2.morphologyEx(mask_b, cv2.MORPH_OPEN, k, iterations=1)

    points = []
    for mask,label in [(mask_r,'B'), (mask_b,'P')]:
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area < 12:  # skip noise; å¯è°ƒæ•´
                continue
            M = cv2.moments(cnt)
            if M['m00'] == 0: continue
            cx = int(M['m10']/M['m00'])
            cy = int(M['m01']/M['m00'])
            points.append((cx, cy, label))
    return points

# ------------------ èšç±»ä¸ºæ¡Œå­åŒºåŸŸï¼ˆå¯å‘å¼ï¼‰ ------------------
def cluster_to_regions(points, img_w, img_h):
    if not points:
        return []
    # coarse grid based clustering
    cell = max(64, int(min(img_w, img_h)/12))
    cols = math.ceil(img_w / cell); rows = math.ceil(img_h / cell)
    grid_counts = [[0]*cols for _ in range(rows)]
    for (x,y,_) in points:
        cx = min(cols-1, x // cell)
        cy = min(rows-1, y // cell)
        grid_counts[cy][cx] += 1
    # find high-density cells
    thr = 6
    hits = [(r,c) for r in range(rows) for c in range(cols) if grid_counts[r][c] >= thr]
    if not hits:
        # fallback: kmeans on points positions
        pts = np.array([[p[0], p[1]] for p in points])
        k = min(8, max(1, len(points)//8))
        try:
            km = KMeans(n_clusters=k, random_state=0).fit(pts)
            regs = []
            for lab in range(k):
                sel = pts[km.labels_==lab]
                if sel.shape[0]==0: continue
                x0,y0 = sel.min(axis=0); x1,y1 = sel.max(axis=0)
                regs.append((int(max(0,x0-10)), int(max(0,y0-10)), int(min(img_w,x1-x0+20)), int(min(img_h,y1-y0+20))))
            return regs
        except Exception:
            return []
    # merge hits to rectangles
    rects = []
    for (r,c) in hits:
        x = c*cell; y = r*cell; w = cell; h = cell
        merged = False
        for i,(rx,ry,rw,rh) in enumerate(rects):
            if not (x > rx+rw+cell or x+w < rx-cell or y > ry+rh+cell or y+h < ry-cell):
                nx = min(rx,x); ny = min(ry,y)
                nw = max(rx+rw, x+w) - nx
                nh = max(ry+rh, y+h) - ny
                rects[i] = (nx,ny,nw,nh)
                merged = True
                break
        if not merged:
            rects.append((x,y,w,h))
    # expand slightly
    regs = []
    for (x,y,w,h) in rects:
        nx = max(0, x-10); ny = max(0, y-10)
        nw = min(img_w-nx, w+20); nh = min(img_h-ny, h+20)
        regs.append((int(nx),int(ny),int(nw),int(nh)))
    return regs

# ------------------ åˆ†æå•ä¸ªæ¡Œå­ ------------------
def analyze_region(bgr, region):
    x,y,w,h = region
    crop = bgr[y:y+h, x:x+w]
    pts = detect_points(crop)
    if not pts:
        return {"total":0, "maxRun":0, "category":"empty", "runs":[]}
    # group by approximate column using x coordinate clustering
    xs = [p[0] for p in pts]
    order = sorted(range(len(xs)), key=lambda i: xs[i])
    col_groups = []
    for i in order:
        xi = xs[i]
        placed=False
        for grp in col_groups:
            gx = np.mean([pts[j][0] for j in grp])
            if abs(gx - xi) <= max(8, w//45):
                grp.append(i); placed=True; break
        if not placed:
            col_groups.append([i])
    # for each column, sort by y and produce sequence of colors
    sequences = []
    for grp in col_groups:
        col_pts = sorted([pts[i] for i in grp], key=lambda t: t[1])
        seq = [p[2] for p in col_pts]
        sequences.append(seq)
    # flatten columns: top-down in each column, left->right across columns
    flattened = []
    maxlen = max((len(s) for s in sequences), default=0)
    for r in range(maxlen):
        for col in sequences:
            if r < len(col):
                flattened.append(col[r])
    # compute runs
    runs = []
    if flattened:
        cur_color = flattened[0]; cur_len = 1
        for k in range(1,len(flattened)):
            if flattened[k] == cur_color:
                cur_len += 1
            else:
                runs.append({"color":cur_color, "len":cur_len})
                cur_color = flattened[k]; cur_len = 1
        runs.append({"color":cur_color, "len":cur_len})
    maxRun = max((r["len"] for r in runs), default=0)
    # detect å¤šè¿/è¿ç : count of runs with len>=4
    multi_runs = sum(1 for r in runs if r["len"] >= 4)
    # classify
    category = "other"
    if maxRun >= 10: category = "super_long"
    elif maxRun >= 8: category = "long"
    elif maxRun >= 4: category = "longish"
    elif maxRun == 1: category = "single"
    return {"total":len(flattened), "maxRun":maxRun, "category":category, "runs":runs, "multiRuns":multi_runs}

# ------------------ Playwright: æ‰“å¼€é¡µé¢å¹¶è¿›å…¥å®ç›˜ ------------------
def capture_screenshot_from_dg(play, url, timeout_total=40):
    """
    æ‰“å¼€ urlï¼Œå°è¯•ç‚¹å‡» Free / å…è´¹è¯•ç©ï¼›å¤„ç†å¼¹çª—å¹¶æ‹–åŠ¨å®‰å…¨æ»‘å—ï¼ˆè‹¥å­˜åœ¨ï¼‰ï¼›ç­‰å¾…å®ç›˜åŠ è½½åæˆªå±
    è¿”å›æˆªå›¾ bytes æˆ– None
    """
    browser = play.chromium.launch(headless=True, args=["--no-sandbox","--disable-gpu","--disable-dev-shm-usage"])
    try:
        context = browser.new_context(user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0 Safari/537.36", viewport={"width":1366, "height":768}, locale="en-US")
        # reduce navigator.webdriver
        context.add_init_script("() => { Object.defineProperty(navigator, 'webdriver', {get: () => false}); }")
        page = context.new_page()
        log(f"è®¿é—®: {url}")
        page.goto(url, timeout=20000)
        time.sleep(1.2)
        # try several times to click Free / å…è´¹è¯•ç© or Free text
        clicked=False
        for txt in ["Free", "å…è´¹è¯•ç©", "å…è´¹", "Play Free", "è¯•ç©", "è¿›å…¥"]:
            try:
                loc = page.locator(f"text={txt}")
                if loc.count() > 0:
                    try:
                        loc.first.click(timeout=3000)
                        clicked=True
                        log(f"ç‚¹å‡»æ–‡æœ¬æŒ‰é’®: {txt}")
                        break
                    except Exception:
                        # try JS click
                        page.evaluate("(el) => el.click()", loc.first)
                        clicked = True
                        break
            except Exception:
                continue
        if not clicked:
            # try to click common button elements
            try:
                btn = page.query_selector("button")
                if btn:
                    btn.click(timeout=2000); clicked=True; log("å°è¯•ç‚¹å‡»ç¬¬ä¸€ä¸ª button")
            except Exception:
                pass

        # give time for popup to appear
        time.sleep(1.2)
        # handle slider-like element: attempt known selectors; otherwise attempt to drag an element near center
        try:
            # attempt to find input[type=range] or role=slider
            slider = None
            try:
                slider = page.query_selector("input[type=range]")
            except:
                slider = None
            if not slider:
                try:
                    slider = page.locator("[role=slider]").first
                    if slider.count()==0: slider=None
                except:
                    slider=None
            if slider:
                bb = slider.bounding_box()
                if bb:
                    sx = bb["x"] + 5; sy = bb["y"] + bb["height"]/2
                    ex = bb["x"] + bb["width"] - 5
                    page.mouse.move(sx, sy); page.mouse.down(); page.mouse.move(ex, sy, steps=20); page.mouse.up()
                    log("æ‰¾åˆ° sliderï¼Œå®Œæˆæ‹–åŠ¨")
            else:
                # generic drag attempt: find element with class contains 'slide' or 'drag'
                try:
                    el = page.query_selector("[class*=slide], [class*=drag], [class*=slider]")
                    if el:
                        bb = el.bounding_box()
                        if bb:
                            sx = bb["x"] + 5; sy = bb["y"] + bb["height"]/2
                            ex = bb["x"] + bb["width"] - 5
                            page.mouse.move(sx, sy); page.mouse.down(); page.mouse.move(ex, sy, steps=25); page.mouse.up()
                            log("å°è¯•æ‹–åŠ¨é€šç”¨æ»‘å—å…ƒç´ ")
                    else:
                        # fallback: attempt to drag a visible small rectangle near center bottom
                        wv = page.viewport_size
                        if wv:
                            sx = wv['width']*0.25; sy = wv['height']*0.6
                            ex = wv['width']*0.75
                            page.mouse.move(sx, sy); page.mouse.down(); page.mouse.move(ex, sy, steps=25); page.mouse.up()
                            log("å°è¯•é€šç”¨åŒºåŸŸæ»‘åŠ¨ï¼ˆfallbackï¼‰")
                except Exception as e:
                    log(f"æ»‘å—æ‹–åŠ¨å°è¯•å¤±è´¥: {e}")
        except Exception as e:
            log(f"æ»‘å—é€»è¾‘å¼‚å¸¸: {e}")

        # allow time for game panel to load
        time.sleep(4)
        # Try to detect presence of game grids: look for many colored circles via JS -> take screenshot
        shot = page.screenshot(full_page=True)
        log("å·²æˆªå›¾å¹¶è¿”å›")
        try:
            context.close()
        except:
            pass
        return shot
    finally:
        try:
            browser.close()
        except:
            pass

# ------------------ ä¾æ®æ¯æ¡Œç»Ÿè®¡åšæ•´ä½“åˆ¤å®š ------------------
def classify_overall(board_stats):
    longCount = sum(1 for b in board_stats if b['category'] in ('long','super_long'))
    superCount = sum(1 for b in board_stats if b['category']=='super_long')
    multi_count = sum(1 for b in board_stats if b.get('multiRuns',0) >= 3)  # æ¯æ¡Œè‡³å°‘3ä¸ªå¤šè¿ï¼ˆ>=4ï¼‰çš„ run
    longish_count = sum(1 for b in board_stats if b['category']=='longish')
    totals = [b['total'] for b in board_stats]
    sparse = sum(1 for t in totals if t < 6)
    n = len(board_stats)
    # æ”¾æ°´æ—¶æ®µï¼šè‡³å°‘ MIN_BOARDS_FOR_PAW å¼ ä¸º é•¿é¾™/è¶…é•¿é¾™ï¼ˆ>=8ï¼‰
    if longCount >= MIN_BOARDS_FOR_PAW:
        return "æ”¾æ°´æ—¶æ®µï¼ˆæé«˜èƒœç‡ï¼‰", longCount, superCount
    # ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Šï¼‰: è‡³å°‘ 3 å¼ æ¡Œå­æ»¡è¶³â€œè¿ç»­3æ’å¤šè¿/è¿ç â€ï¼ˆæˆ‘ä»¬å®šä¹‰ä¸ºå•æ¡Œ multiRuns>=3ï¼‰ï¼Œå¹¶ä¸”è‡³å°‘ 2 å¼ æ¡Œå­ä¸ºé•¿é¾™/è¶…é•¿é¾™ï¼ˆ>=8ï¼‰
    cond1 = multi_count >= 3
    cond2 = longCount >= MID_LONG_REQ
    if cond1 and cond2:
        return "ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Šï¼‰", longCount, superCount
    # è‹¥å¤šæ•°æ¡Œç©ºæ—· -> æ”¶å‰²
    if n>0 and sparse >= n*0.6:
        return "èƒœç‡è°ƒä½ / æ”¶å‰²æ—¶æ®µ", longCount, superCount
    return "èƒœç‡ä¸­ç­‰ï¼ˆå¹³å°æ”¶å‰²ä¸­ç­‰æ—¶æ®µï¼‰", longCount, superCount

# ------------------ ä¸»æµç¨‹ ------------------
def main():
    global TG_BOT_TOKEN, TG_CHAT_ID
    log("å¼€å§‹æ£€æµ‹å¾ªç¯...")
    state = load_state()
    screenshot = None
    with sync_playwright() as p:
        # try both links with retries
        for url in DG_LINKS:
            try:
                for attempt in range(2):
                    shot = capture_screenshot_from_dg(p, url)
                    if shot:
                        screenshot = shot
                        break
                    time.sleep(1.5)
                if screenshot: break
            except Exception as e:
                log(f"è®¿é—® {url} æ—¶å¤±è´¥: {e}")
                continue

    if not screenshot:
        log("æ— æ³•è·å¾—å®ç›˜æˆªå›¾ï¼Œæœ¬æ¬¡ç»“æŸã€‚")
        save_state(state)
        return

    pil = pil_from_bytes(screenshot)
    bgr = cv_from_pil(pil)
    h,w = bgr.shape[:2]
    points = detect_points(bgr)
    log(f"æ£€æµ‹åˆ°å½©ç‚¹æ•°é‡: {len(points)}")
    if len(points) < 8:
        log("å½©ç‚¹åå°‘ï¼ˆå¯èƒ½ç•Œé¢æœªè¿›å…¥å®ç›˜æˆ–è¯†åˆ«é—¨æ§›ï¼‰ï¼Œæœ¬æ¬¡ä¸åˆ¤å®šã€‚")
        save_state(state)
        return

    regions = cluster_to_regions(points, w, h)
    log(f"èšç±»å‡ºå€™é€‰å°æ¡Œ: {len(regions)}")
    board_stats = []
    for idx, reg in enumerate(regions):
        st = analyze_region(bgr, reg)
        st['region_idx'] = idx+1
        board_stats.append(st)

    overall, longCount, superCount = classify_overall(board_stats)
    log(f"æœ¬æ¬¡åˆ¤å®š => {overall} ï¼ˆé•¿/è¶…é•¿é¾™æ¡Œæ•°={longCount}ï¼Œè¶…é•¿é¾™={superCount}ï¼‰")

    now_iso = datetime.now(TZ).isoformat()
    was_active = state.get("active", False)
    was_kind = state.get("kind", None)
    is_active_now = overall in ("æ”¾æ°´æ—¶æ®µï¼ˆæé«˜èƒœç‡ï¼‰", "ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Š)".replace(")","")) or overall in ("æ”¾æ°´æ—¶æ®µï¼ˆæé«˜èƒœç‡ï¼‰", "ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Šï¼‰")

    # normalize flag: check two specific strings
    is_active_now = overall in ("æ”¾æ°´æ—¶æ®µï¼ˆæé«˜èƒœç‡ï¼‰", "ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Šï¼‰")

    # state transitions
    if is_active_now and not was_active:
        # start new event
        history = state.get("history", [])
        # estimate duration from history mean
        if history:
            durations = [h.get("duration_minutes",0) for h in history if h.get("duration_minutes",0)>0]
            est_minutes = round(sum(durations)/len(durations)) if durations else 10
        else:
            est_minutes = 10
        est_end_dt = datetime.now(TZ) + timedelta(minutes=est_minutes)
        est_end_str = est_end_dt.strftime("%Y-%m-%d %H:%M:%S")
        emoji = "ğŸš©"
        msg = f"{emoji} <b>DG æé†’ â€” {overall}</b>\nåµæ¸¬æ™‚é–“ (MYT): {now_iso}\né•·/è¶…é•¿é¾™æ¡Œæ•¸={longCount}ï¼Œè¶…é•¿é¾™={superCount}\nä¼°è¨ˆçµæŸæ™‚é–“: {est_end_str} ï¼ˆç´„ {est_minutes} åˆ†é˜ï¼‰\n\næé†’ï¼šæ­¤ç‚ºç³»çµ±å¯¦æ™‚åµæ¸¬ï¼Œè«‹æ‰‹å‹•é€²å ´ç¢ºèªå¯¦æ³ã€‚"
        send_telegram(msg)
        # update state
        state = {"active":True, "kind":overall, "start_time": now_iso, "last_seen": now_iso, "history": state.get("history", [])}
        save_state(state)
        log("é–‹å§‹äº‹ä»¶å·²è¨˜éŒ„ä¸¦ç™¼é€ Telegramï¼ˆè‹¥é…ç½®ï¼‰ã€‚")
    elif is_active_now and was_active:
        state["last_seen"] = now_iso
        state["kind"] = overall
        save_state(state)
        log("äº‹ä»¶æŒçºŒä¸­ï¼Œæ›´æ–° last_seenã€‚")
    elif (not is_active_now) and was_active:
        # ended
        start = datetime.fromisoformat(state.get("start_time"))
        end = datetime.now(TZ)
        duration_min = round((end - start).total_seconds()/60)
        entry = {"kind": state.get("kind"), "start_time": state.get("start_time"), "end_time": end.isoformat(), "duration_minutes": duration_min}
        hist = state.get("history", [])
        hist.append(entry)
        hist = hist[-120:]
        new_state = {"active": False, "kind": None, "start_time": None, "last_seen": None, "history": hist}
        save_state(new_state)
        emoji = "âœ…"
        msg = f"{emoji} <b>DG æé†’ â€” {state.get('kind')} å·²çµæŸ</b>\né–‹å§‹: {entry['start_time']}\nçµæŸ: {entry['end_time']}\nå¯¦éš›æŒçºŒ: {duration_min} åˆ†é˜"
        send_telegram(msg)
        log("äº‹ä»¶çµæŸå·²ç™¼é€é€šçŸ¥ä¸¦ä¿å­˜æ­·å²ã€‚")
    else:
        # not active, do nothing
        save_state(state)
        log("ç›®å‰æœªè™•æ–¼æ”¾æ°´/ä¸­ä¸Šæ™‚æ®µï¼Œä¸ç™¼æé†’ã€‚")

    # write last_run_summary for debugging
    debug = {"ts": now_iso, "overall": overall, "longCount": longCount, "superCount": superCount, "boards": board_stats[:50]}
    Path(LAST_SUMMARY).write_text(json.dumps(debug, ensure_ascii=False, indent=2), encoding="utf-8")
    log("æœ¬æ¬¡æ‘˜è¦å·²å¯«å…¥ last_run_summary.json")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        log(f"ä¸»ç¨‹å¼ä¾‹å¤–: {e}")
        raise
