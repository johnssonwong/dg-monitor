# scripts/dg_detector.py
import os
import time
import json
import math
import subprocess
from datetime import datetime, timezone, timedelta
from pathlib import Path
import requests
from PIL import Image
import io
import numpy as np
import cv2

# Playwright synchronous API
from playwright.sync_api import sync_playwright

# ------------- é…ç½®å‚æ•°ï¼ˆå¯ä¿®æ”¹ï¼‰ -------------
# è¿™äº›å‚æ•°å·²æŒ‰ç…§ä½ çš„å®šä¹‰ï¼š
LONG_LIAN = 4        # è¿ç»­>=4 ç²’ = é•¿è¿
CHANG_LONG = 8       # è¿ç»­>=8 ç²’ = é•¿é¾™
SUPER_CHANG = 10     # è¿ç»­>=10 ç²’ = è¶…é•¿é¾™
DOUBLE_JUMP_MAX = 3  # 2~3 ç²’ = åŒè·³
# æ•´ä¸ªé¡µé¢åˆ¤å®šé˜ˆå€¼ï¼ˆä¸ä½ è®¾å®šä¸€è‡´ï¼‰
MIN_TABLES_FOR_PERCENT = 0.50  # >=50% ç¬¦åˆé•¿è¿/é•¿é¾™ è§†ä¸ºæ”¾æ°´

# ------------- ç¯å¢ƒå˜é‡ï¼ˆæ¥è‡ª GitHub Secretsï¼‰ -------------
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "").strip()
DG_URLS = os.getenv("DG_URLS", "https://dg18.co/ https://dg18.co/wap/").split()
# ç”¨äº commit state.json çš„ git user
GIT_USER_NAME = "dg-detector[bot]"
GIT_USER_EMAIL = "dg-detector-bot@example.com"
REPO_ROOT = Path(__file__).resolve().parents[1]
STATE_FILE = REPO_ROOT / "state.json"

# ------------- å·¥å…·å‡½æ•° -------------
def send_telegram_message(text, image_bytes=None, filename="dg_snapshot.png"):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        print("Telegram token/chat not set. Skipping send.")
        return False
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    # send text first, then send photo (so text always delivered)
    resp = requests.post(url, json={"chat_id": TELEGRAM_CHAT_ID, "text": text, "parse_mode": "HTML"})
    ok = resp.ok
    if image_bytes:
        files = {"photo": (filename, image_bytes)}
        photo_url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto"
        resp2 = requests.post(photo_url, data={"chat_id": TELEGRAM_CHAT_ID, "caption": filename}, files=files)
        ok = ok and resp2.ok
    print("Telegram send:", ok)
    return ok

def load_state():
    if STATE_FILE.exists():
        try:
            return json.loads(STATE_FILE.read_text(encoding="utf-8"))
        except:
            pass
    # default
    return {"in_run": False, "run_type": None, "start_ts": None}

def save_state_and_commit(state):
    # write state file
    STATE_FILE.write_text(json.dumps(state, ensure_ascii=False, indent=2), encoding="utf-8")
    # commit the change back to repo using provided GITHUB_TOKEN (the workflow supplies it)
    try:
        subprocess.run(["git", "config", "user.email", GIT_USER_EMAIL], check=True)
        subprocess.run(["git", "config", "user.name", GIT_USER_NAME], check=True)
        subprocess.run(["git", "add", str(STATE_FILE)], check=True)
        subprocess.run(["git", "commit", "-m", f"Update detector state: {state}"], check=True)
        subprocess.run(["git", "push"], check=True)
        print("State saved and committed.")
    except Exception as e:
        print("Commit failed:", e)

# ------------- å›¾åƒå¤„ç†ï¼šç®€å•é¢œè‰²æ£€æµ‹ + è¿ç»­è®¡æ•°ï¼ˆå¯å‘å¼ï¼‰ -------------
# å› ä¸ºä¸åŒå¹³å°å›¾å½¢ç»†èŠ‚ä¼šä¸åŒï¼Œä¸‹é¢ä½¿ç”¨é¢œè‰²é˜ˆå€¼ï¼ˆBGR/HSVï¼‰æ£€æµ‹çº¢/è“åœ†ç‚¹ï¼Œå†èšç±»ä¸ºè¡¨æ ¼åŒºåŸŸã€‚
def analyze_image_for_tables(img_bytes):
    """
    è¾“å…¥ï¼šæ•´é¡µæˆªå›¾ bytes
    è¾“å‡ºï¼š{
      'tables': [ { 'bbox':(x,y,w,h), 'runs': [list of columns runs info], 'max_run_len': int, 'type_flags': {...} }, ... ],
      'summary': {...}
    }
    è¯´æ˜ï¼šæ­¤å‡½æ•°å°½é‡æ³›åŒ–å¯¹â€œç™½è‰²æ¡†å†…çº¢è‰²/è“è‰²åœ†åœˆâ€çš„æ£€æµ‹ï¼Œè¿”å›æ¯æ¡Œæœ€å¤§è¿ç»­é•¿åº¦ç­‰æ•°å€¼
    """
    arr = np.frombuffer(img_bytes, dtype=np.uint8)
    img = cv2.imdecode(arr, flags=cv2.IMREAD_COLOR)
    h, w = img.shape[:2]
    # convert to HSV for stable color detection
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

    # red and blue masks (broad)
    # red has two ranges in HSV
    lower_red1 = np.array([0, 80, 50]); upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([160, 80, 50]); upper_red2 = np.array([179, 255, 255])
    mask_r1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask_r2 = cv2.inRange(hsv, lower_red2, upper_red2)
    mask_red = cv2.bitwise_or(mask_r1, mask_r2)
    # blue
    lower_blue = np.array([90, 60, 40]); upper_blue = np.array([140, 255, 255])
    mask_blue = cv2.inRange(hsv, lower_blue, upper_blue)

    # find red/blue contours (these correspond roughly to circles)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))
    mr = cv2.morphologyEx(mask_red, cv2.MORPH_OPEN, kernel, iterations=1)
    mb = cv2.morphologyEx(mask_blue, cv2.MORPH_OPEN, kernel, iterations=1)

    # combine to show where markers are
    both = cv2.bitwise_or(mr, mb)
    # find connected components to cluster candidate regions (likely table areas)
    num_labels, labels_im = cv2.connectedComponents(both)
    regions = []
    for lab in range(1, num_labels):
        mask = (labels_im == lab).astype("uint8") * 255
        ys, xs = np.where(mask)
        if len(xs) < 30 or len(ys) < 30:
            continue
        x0, x1 = xs.min(), xs.max()
        y0, y1 = ys.min(), ys.max()
        # filter very large (maybe entire page) or tiny
        wbox, hbox = x1-x0, y1-y0
        if wbox < 50 or hbox < 50:
            continue
        if wbox*hbox > 0.9*w*h:  # skip almost-full image
            continue
        regions.append((x0,y0,wbox,hbox))
    # if no regions found, fallback to detect by grid-like layout: try to split page into likely table boxes
    if not regions:
        # fallback: split into a grid of 4x4 upper-left region scanning
        grid_boxes = []
        rows = 4
        cols = 3
        ph = h // rows
        pw = w // cols
        for r in range(rows):
            for c in range(cols):
                grid_boxes.append((c*pw, r*ph, pw, ph))
        regions = grid_boxes

    # For each region, count red/blue markers and estimate run-length along columns
    tables = []
    for (x,y,wb,hb) in regions:
        sub = img[y:y+hb, x:x+wb]
        hsv_sub = cv2.cvtColor(sub, cv2.COLOR_BGR2HSV)
        mr_sub = cv2.inRange(hsv_sub, lower_red1, upper_red1) | cv2.inRange(hsv_sub, lower_red2, upper_red2)
        mb_sub = cv2.inRange(hsv_sub, lower_blue, upper_blue)
        # detect centroids of markers
        cnts_r = cv2.findContours(mr_sub, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]
        cnts_b = cv2.findContours(mb_sub, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]
        pts = []
        for c in cnts_r:
            (cx,cy,wc,hc) = cv2.boundingRect(c)
            if wc*hc < 10: continue
            pts.append((cx+wc//2, cy+hc//2, 'B'))  # B=Banker(red)
        for c in cnts_b:
            (cx,cy,wc,hc) = cv2.boundingRect(c)
            if wc*hc < 10: continue
            pts.append((cx+wc//2, cy+hc//2, 'P'))  # P=Player(blue)
        if not pts:
            # no markers in region => likely empty table
            tables.append({'bbox':(x,y,wb,hb), 'marker_count':0, 'max_run_len':0, 'runs':[], 'type_flags':{}})
            continue
        # Cluster markers by approximate column (x coordinate) to reconstruct columns top-down
        pts_sorted = sorted(pts, key=lambda p:(p[0], p[1]))
        # quantize columns by x position
        xs = [p[0] for p in pts_sorted]
        if len(xs) == 0:
            tables.append({'bbox':(x,y,wb,hb), 'marker_count':0, 'max_run_len':0, 'runs':[], 'type_flags':{}})
            continue
        # cluster xs into columns
        col_thresh = max(10, wb//20)
        columns = []
        for px,py,pc in pts_sorted:
            placed=False
            for col in columns:
                if abs(col['x'] - px) <= col_thresh:
                    col['pts'].append((px,py,pc))
                    placed=True
                    break
            if not placed:
                columns.append({'x':px, 'pts':[(px,py,pc)]})
        # for each column, sort by y top->bottom and create run string
        runs = []
        max_run_len = 0
        for col in columns:
            col['pts'].sort(key=lambda t:t[1])  # top->bottom
            # generate simplified sequence by collapsing vertically near duplicates
            seq = []
            last_y = None
            for px,py,pc in col['pts']:
                if last_y is None or abs(py-last_y) > 6:
                    seq.append(pc)
                    last_y = py
            runs.append(seq)
            # compute max consecutive in this column
            cur = seq[0] if seq else None
            cur_len = 1 if seq else 0
            local_max = 0
            for i in range(1, len(seq)):
                if seq[i] == seq[i-1]:
                    cur_len += 1
                else:
                    local_max = max(local_max, cur_len)
                    cur_len = 1
            local_max = max(local_max, cur_len)
            max_run_len = max(max_run_len, local_max)
        # determine flags per user definitions
        type_flags = {}
        type_flags['long_lian'] = max_run_len >= LONG_LIAN
        type_flags['chang_long'] = max_run_len >= CHANG_LONG
        type_flags['super_chang'] = max_run_len >= SUPER_CHANG
        tables.append({
            'bbox':(x,y,wb,hb),
            'marker_count':len(pts),
            'max_run_len':int(max_run_len),
            'runs':runs,
            'type_flags':type_flags
        })
    # produce summary counts
    total_tables = len(tables)
    n_long = sum(1 for t in tables if t['type_flags'].get('long_lian'))
    n_chang = sum(1 for t in tables if t['type_flags'].get('chang_long'))
    n_super = sum(1 for t in tables if t['type_flags'].get('super_chang'))
    summary = {'total_tables': total_tables, 'n_long': n_long, 'n_chang': n_chang, 'n_super': n_super}
    return {'tables': tables, 'summary': summary}

# ------------- åˆ¤å®šé€»è¾‘ï¼ˆä½ ç»™çš„è§„åˆ™å®Œå…¨å®ç°ï¼‰ -------------
def classify_scene(analysis):
    summ = analysis['summary']
    total = summ['total_tables'] if summ['total_tables']>0 else 1
    pct_long = summ['n_long'] / total
    # Rule 1: æ”¾æ°´ï¼ˆèƒœç‡è°ƒé«˜ï¼‰
    # - æ»¡æ¡Œé•¿è¿/é•¿é¾™ç±»å‹ï¼šè‹¥ >= 50% æ¡Œå­ä¸ºé•¿è¿/é•¿é¾™ => æ”¾æ°´
    # - æˆ–è€… è¶…é•¿é¾™ + å¦å¤–è‡³å°‘ 2 å¼ ä¸ºé•¿é¾™ => æ”¾æ°´
    is_full_long = pct_long >= MIN_TABLES_FOR_PERCENT
    is_super_combo = (summ['n_super'] >= 1 and summ['n_chang'] >= 2)
    if is_full_long or is_super_combo:
        return ('æ”¾æ°´', {'pct_long':pct_long, 'n_chang':summ['n_chang'], 'n_super':summ['n_super']})
    # Rule 2: ä¸­ç­‰å‹ç‡ï¼ˆä¸­ä¸Šï¼‰
    # å®šä¹‰ï¼šæ”¾æ°´ç‰¹å¾å æ¯”ä¸è¶³ 50% ä½†æ··åˆå‡ºç°ï¼ˆä¾‹å¦‚æœ‰ >=2 æ¡Œé•¿é¾™ï¼Œä¸”ä¸å°‘é•¿è¿ï¼‰
    if summ['n_chang'] >= 2 or (pct_long >= 0.30 and summ['n_chang'] >= 1):
        return ('ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Šï¼‰', {'pct_long':pct_long, 'n_chang':summ['n_chang'], 'n_super':summ['n_super']})
    # Rule 3: èƒœç‡ä¸­ç­‰ï¼ˆæ”¶å‰²ä¸­ç­‰ï¼‰
    # å¤§é‡å•è·³ã€å›¾é¢ç©ºè¡ã€è¿å°‘
    # Here we use heuristics: if many tables have marker_count small and max_run_len < LONG_LIAN
    tables = analysis['tables']
    empty_tables = sum(1 for t in tables if t['marker_count'] < 6 or t['max_run_len'] < LONG_LIAN)
    pct_empty = empty_tables / total
    if pct_empty >= 0.6:
        return ('èƒœç‡ä¸­ç­‰', {'pct_empty':pct_empty})
    # Rule 4: èƒœç‡è°ƒä½ï¼ˆæ”¶å‰²æ—¶æ®µï¼‰
    # if almost none have long runs
    if summ['n_chang'] < 1 and pct_long < 0.15:
        return ('æ”¶å‰²æ—¶æ®µ', {'pct_long':pct_long})
    # default fallback
    return ('èƒœç‡ä¸­ç­‰', {'pct_long':pct_long, 'n_chang':summ['n_chang'], 'n_super':summ['n_super']})

# ------------- æ”¾æ°´æ—¶é•¿ä¼°ç®—ï¼ˆå¯å‘å¼ï¼‰ -------------
def estimate_remaining_minutes(analysis, scene_type):
    # ç”±äºæ— æ³•ç²¾ç¡®é¢„æµ‹ï¼Œæˆ‘ä»¬ç”¨ä»¥ä¸‹å¯å‘å¼ä¼°ç®—ï¼š
    # - æ‰¾åˆ°å½“å‰æ‰€æœ‰ max_run_lenï¼Œå¹¶å–å¹³å‡ï¼ˆä»£è¡¨å¹³å°æœ¬æ¬¡â€œå€¾å‘â€çš„è¿é•¿ï¼‰
    # - è‹¥æœ‰è¶…é•¿é¾™ï¼Œå‡è®¾è¿˜ä¼šæŒç»­ avg_len - current_len è½®ï¼ˆè‹¥ >0ï¼‰ï¼Œå¹¶å‡è®¾ 1 è½® ~ 1 åˆ†é’Ÿï¼ˆå®é™…æ ¹æ®ä½ è§‚å¯Ÿå¯è°ƒï¼‰
    tables = analysis['tables']
    lens = [t['max_run_len'] for t in tables if t['max_run_len']>0]
    if not lens:
        return 0, "æ— æ³•ä¼°ç®—ï¼ˆæ ‡è®°ï¼šæ— è¿ç æ ·æœ¬ï¼‰"
    avg_len = sum(lens)/len(lens)
    # å½“å‰æœ€é•¿åˆ—
    cur_max = max(lens)
    # ä¼°ç®—å‰©ä½™å›åˆæ•°
    remaining_rounds = max(0, int(round(avg_len - cur_max)))
    # å‡è®¾æ¯å±€çº¦ 1 åˆ†é’Ÿï¼ˆè¿™æ˜¯è¿‘ä¼¼ï¼›å„èµŒåœºå‡ºç‰Œé—´éš”ä¸åŒï¼›ä½ å¯ä»¥è°ƒæ•´ï¼‰
    est_minutes = remaining_rounds * 1
    # minimal fallbackï¼šè‹¥æ£€æµ‹åˆ°è¶…é•¿é¾™/é•¿é¾™ï¼Œè‡³å°‘ç»™ 5 åˆ†é’Ÿ
    if scene_type == 'æ”¾æ°´' and est_minutes < 5:
        est_minutes = 5
    return est_minutes, f"ä¼°ç®—åŸºäºå½“å‰æ¡Œé¢å¹³å‡è¿é•¿={avg_len:.1f}, å½“å‰æœ€å¤§={cur_max}, ä¼°ç®—å‰©ä½™è½®æ•°={remaining_rounds}"

# ------------- ä¸»æµç¨‹ -------------
def run_detector_once():
    # 1) è®¿é—® DG é¡µé¢å¹¶æˆªå›¾
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True, args=["--no-sandbox"])
        context = browser.new_context(viewport={"width":1400,"height":900})
        page = context.new_page()

        screenshot_bytes = None
        for url in DG_URLS:
            try:
                print("å°è¯•æ‰“å¼€", url)
                page.goto(url, timeout=30000)
                # ç­‰å¾…é¡µé¢ç¨³å®š
                page.wait_for_timeout(2500)
                # æ‰¾â€œFreeâ€æˆ–â€œå…è´¹è¯•ç©â€æŒ‰é’®å¹¶ç‚¹å‡»ï¼ˆå¤šç§å°è¯•ç­–ç•¥ï¼‰
                try:
                    # æ‰¾å¸¦ Free æ–‡æœ¬çš„æŒ‰é’®
                    btn = page.locator("text=Free, text=å…è´¹è¯•ç©").first
                    if btn:
                        btn.click(timeout=3000)
                        page.wait_for_timeout(2000)
                except Exception as e:
                    print("æœªæ‰¾åˆ°FreeæŒ‰é”®æˆ–ç‚¹å‡»å¤±è´¥ï¼š", e)
                # å¦‚æœå¼¹å‡ºæ–°é¡µé¢ï¼ˆtarget=_blankï¼‰ï¼Œåˆ‡æ¢åˆ°æ–°é¡µé¢
                pages = context.pages
                pg = pages[-1]
                try:
                    # å¯»æ‰¾å®‰å…¨æ»‘å—ï¼ˆé€šå¸¸ä¸º class æˆ– idï¼‰ï¼Œå°è¯•æ‹–åŠ¨
                    # é‡‡ç”¨æ³›åŒ–ç­–ç•¥ï¼šå¯»æ‰¾ input[type=range] æˆ–å¯æ‹–æ‹½å…ƒç´ 
                    slider = None
                    try:
                        slider = pg.locator("input[type=range]").first
                    except:
                        slider = None
                    if slider and slider.count() > 0:
                        box = slider.bounding_box()
                        if box:
                            x = box['x'] + 2
                            y = box['y'] + box['height']/2
                            pg.mouse.move(x,y)
                            pg.mouse.down()
                            pg.mouse.move(x+box['width']*0.9, y, steps=10)
                            pg.mouse.up()
                            pg.wait_for_timeout(1200)
                except Exception as ee:
                    print("slider try failed:", ee)
                # ç­‰å¾…ä¸»è¦æ¡Œé¢è½½å…¥ï¼ˆæ­¤å¤„å°è¯•ç­‰å¾…å¯èƒ½åŒ…å«â€œtable gridâ€æˆ–å¤§é‡ canvasï¼‰
                pg.wait_for_timeout(2000)
                # æœ€åæˆªå– fullPage screenshotï¼ˆè‹¥æ— æ³• fullPageï¼Œåˆ™viewportï¼‰
                try:
                    screenshot_bytes = pg.screenshot(full_page=True)
                except:
                    screenshot_bytes = pg.screenshot()
                # å¦‚æœè·å¾—æˆªå›¾ï¼Œåˆ™é€€å‡ºå¾ªç¯
                if screenshot_bytes:
                    print("æˆªå›¾æˆåŠŸï¼Œé•¿åº¦ï¼š", len(screenshot_bytes))
                    break
            except Exception as e:
                print("æ‰“å¼€ url å¤±è´¥ï¼š", e)
        browser.close()

    if not screenshot_bytes:
        raise RuntimeError("æ— æ³•ä» DG è·å–æˆªå›¾ã€‚è¯·ç¡®è®¤é“¾æ¥å¯è®¿é—®æˆ– Free æµç¨‹æ˜¯å¦æœ‰å˜åŒ–ã€‚")

    # 2) åˆ†ææˆªå›¾
    analysis = analyze_image_for_tables(screenshot_bytes)
    scene_type, details = classify_scene(analysis)
    est_min, est_reason = estimate_remaining_minutes(analysis, scene_type)

    # 3) æ ¹æ® state.json å†³å®šæ˜¯å¦å‘é€é€šçŸ¥ï¼ˆä»…åœ¨æ”¾æ°´æˆ–ä¸­ç­‰(ä¸­ä¸Š) æ—¶å‘é€ï¼‰
    state = load_state()
    now_ts = datetime.now(timezone.utc).timestamp()
    # If scene_type is æ”¾æ°´ or ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Šï¼‰ => should notify (æ”¾æ°´å¼ºæé†’ï¼›ä¸­ä¸Šå°æé†’)
    notify_types = ['æ”¾æ°´', 'ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Šï¼‰']
    send_notice = False
    notice_type = None
    if scene_type in notify_types:
        if not state.get('in_run'):
            # start new run
            send_notice = True
            notice_type = 'start'
            state['in_run'] = True
            state['run_type'] = scene_type
            state['start_ts'] = now_ts
            state['last_scene'] = scene_type
        else:
            # already in run â€” only send start once; otherwise skip repeated notifications
            # But if previously run_type different and now stronger (æ¯”å¦‚ä» ä¸­ç­‰->æ”¾æ°´), send upgrade notice
            if state.get('run_type') != scene_type:
                send_notice = True
                notice_type = 'upgrade'
                state['run_type'] = scene_type
                state['last_scene'] = scene_type
    else:
        # current scene NOT a notify type
        if state.get('in_run'):
            # Previously was in run -> now ended
            send_notice = True
            notice_type = 'end'
            start_ts = state.get('start_ts')
            state['in_run'] = False
            state['last_scene'] = scene_type
            # compute duration minutes
            dur_minutes = int(round((now_ts - (start_ts or now_ts))/60))
            state['last_run_duration_min'] = dur_minutes
            state['run_type'] = None
            state['start_ts'] = None

    # 4) å»ºç«‹é€šçŸ¥æ–‡å­—
    now_local = datetime.now(tz=timezone.utc).astimezone(tz=timezone(timedelta(hours=8))) # Malaysia +8
    msg_lines = []
    msg_lines.append(f"ğŸ“Š <b>DG å±€åŠ¿æ£€æµ‹</b> ï¼ˆ{now_local.strftime('%Y-%m-%d %H:%M:%S')} é©¬æ¥è¥¿äºšæ—¶é—´ï¼‰")
    msg_lines.append(f"æ£€æµ‹ç»“æœï¼š<b>{scene_type}</b>")
    if isinstance(details, dict):
        msg_lines.append("è¯¦æƒ…ï¼š" + ", ".join([f"{k}={v}" for k,v in details.items()]))
    msg_lines.append(f"æ£€æµ‹æ¡Œæ•°ï¼š {analysis['summary']['total_tables']}, é•¿è¿æ¡Œæ•°ï¼š{analysis['summary']['n_long']}, é•¿é¾™ï¼š{analysis['summary']['n_chang']}, è¶…é¾™ï¼š{analysis['summary']['n_super']}")
    if scene_type in notify_types:
        msg_lines.append(f"æé†’çº§åˆ«ï¼š{'å¿…é¡»æé†’ï¼ˆæ”¾æ°´ï¼‰' if scene_type=='æ”¾æ°´' else 'å°æé†’ï¼ˆä¸­ç­‰èƒœç‡ ä¸­ä¸Šï¼‰'}")
        if est_min>0:
            est_end = now_local + timedelta(minutes=est_min)
            msg_lines.append(f"ä¼°è®¡æ”¾æ°´/æŒç»­å‰©ä½™ï¼š{est_min} åˆ†é’Ÿï¼Œé¢„è®¡ç»“æŸæ—¶é—´ï¼š{est_end.strftime('%H:%M:%S')}ï¼ˆä¼°ç®—ï¼‰")
        else:
            msg_lines.append("ä¼°è®¡æ”¾æ°´å‰©ä½™ï¼šæ— æ³•ç²¾ç¡®ä¼°ç®—ï¼ˆæ ·æœ¬ä¸è¶³ï¼‰")
    if notice_type=='start':
        msg_lines.insert(0, "ğŸ”” <b>æ”¾æ°´/ä¸­ä¸Šæ—¶æ®µ å·²æ£€æµ‹åˆ°ï¼ˆå¼€å§‹ï¼‰</b>")
    elif notice_type=='upgrade':
        msg_lines.insert(0, "ğŸ”º <b>æ—¶æ®µå‡çº§é€šçŸ¥</b>")
    elif notice_type=='end':
        dur = state.get('last_run_duration_min', 0)
        msg_lines.insert(0, f"âœ… <b>æ”¾æ°´å·²ç»“æŸ</b>ï¼Œå…±æŒç»­ {dur} åˆ†é’Ÿï¼ˆå®æµ‹ï¼‰")

    text = "\n".join(msg_lines)

    # 5) å¦‚æœéœ€è¦å‘é€æé†’æˆ–ç»“æŸé€šçŸ¥ï¼Œåˆ™å‘ Telegram å¹¶é™„ä¸Šæˆªå›¾
    if send_notice:
        # send screenshot too
        image_bytes = screenshot_bytes
        send_telegram_message(text, image_bytes=image_bytes)
    else:
        print("æœªè§¦å‘é€šçŸ¥ã€‚å½“å‰ scene:", scene_type)

    # 6) ä¿å­˜ stateï¼ˆå¹¶ commitï¼‰
    try:
        save_state_and_commit(state)
    except Exception as e:
        print("ä¿å­˜ state å‡ºé”™ï¼š", e)

    # return for logging
    return {"scene":scene_type, "details":details, "est_min":est_min, "est_reason":est_reason}

if __name__ == "__main__":
    try:
        result = run_detector_once()
        print("Detection result:", result)
    except Exception as e:
        print("æ£€æµ‹å¼‚å¸¸ï¼š", e)
        # è‹¥å‘ç”Ÿå¼‚å¸¸ï¼Œå‘é€ Telegram æ–‡å­—å‘ŠçŸ¥ï¼ˆä¸åŒ…å«æˆªå›¾ï¼‰
        try:
            send_telegram_message(f"âš ï¸ DG Detector æ‰§è¡Œå‡ºé”™ï¼š{e}\nè¯·æ£€æŸ¥ workflow æ—¥å¿—ã€‚")
        except:
            pass
        raise
