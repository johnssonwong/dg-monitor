name: DG Monitor 24x7 (Final)

on:
  schedule:
    - cron: "*/5 * * * *"   # æ¯5åˆ†é’Ÿè‡ªåŠ¨è¿è¡Œ
  workflow_dispatch:

permissions:
  contents: write

jobs:
  monitor:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install playwright==1.46.0 opencv-python-headless numpy pillow requests pytz
          python -m playwright install --with-deps chromium

      - name: Write monitor.py (final detector)
        shell: bash
        run: |
          cat > monitor.py << 'PY'
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DG è‡ªåŠ¨ç›‘æµ‹æœ€ç»ˆç‰ˆï¼ˆæŒ‰ç”¨æˆ·æ‰€æœ‰è§„åˆ™æ•´åˆï¼‰
- æ¯æ¬¡è¿è¡Œä¼šï¼šè¿›å…¥ DG ä¸¤ä¸ªå…¥å£ -> ç‚¹å‡» Free/å…è´¹è¯•ç© -> å¤„ç†æ»‘å— -> æˆªå– canvas -> CV è¯†åˆ«çº¢/è“åœˆ -> åˆ¤å®šæ¯æ¡Œï¼ˆé•¿è¿/é•¿é¾™/è¶…é•¿é¾™/å¤šè¿/å•è·³ï¼‰
- åˆ¤å®šæ•´ä½“å±€åŠ¿ï¼šæ”¾æ°´(FANGSHUI)ã€ä¸­ç­‰èƒœç‡(MID_UP)ã€èƒœç‡ä¸­ç­‰(MID)ã€æ”¶å‰²(HARVEST)
- é€šçŸ¥ï¼šTelegramï¼ˆå¼€å§‹/å¿ƒè·³/ç»“æŸ/é”™è¯¯ï¼‰
- æ—¶åŒºï¼šAsia/Kuala_Lumpurï¼ˆé©¬æ¥è¥¿äºšï¼‰
"""

import os, time, json, math, traceback, statistics
from datetime import datetime, timedelta
import pytz
import requests
import numpy as np
import cv2
from playwright.sync_api import sync_playwright

# ========== é…ç½®ï¼ˆå·²å¡«å…¥ç”¨æˆ·ä¿¡æ¯ï¼Œå¯ç”¨ä»“åº“ Secrets è¦†ç›–ç¯å¢ƒå˜é‡ TG_TOKEN/TG_CHAT_IDï¼‰ ==========
TG_TOKEN = os.getenv("TG_TOKEN") or "8134230045:AAH6C_H53R_J2RH98fGTqZFHsjkKALhsTh8"
TG_CHAT_ID = os.getenv("TG_CHAT_ID") or "485427847"
DG_URLS = ["https://dg18.co/wap/", "https://dg18.co/"]
TZ = pytz.timezone("Asia/Kuala_Lumpur")
STATE_FILE = "dg_state.json"

# ========== é€šç”¨å·¥å…· ==========
def now_ms():
    return int(datetime.now(TZ).timestamp() * 1000)

def now_str():
    return datetime.now(TZ).strftime("%Y-%m-%d %H:%M:%S")

def send_telegram(text: str):
    try:
        requests.post(f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage",
                      data={"chat_id": TG_CHAT_ID, "text": text, "parse_mode": "HTML"}, timeout=20)
    except Exception:
        # ä¸é˜»å¡
        pass

# ========== å›¾åƒå¤„ç†ï¼šæ£€æµ‹çº¢/è“åœ†ç‚¹ ==========

def bytes_to_bgr(img_bytes: bytes):
    arr = np.frombuffer(img_bytes, dtype=np.uint8)
    return cv2.imdecode(arr, cv2.IMREAD_COLOR)

def find_red_blue_points(bgr):
    """HSVé˜ˆå€¼ + Hough åœ†æ£€æµ‹æ‰¾çº¢è“ç‚¹"""
    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)
    # çº¢è‰²ï¼ˆåˆ†ä¸¤æ®µï¼‰
    lower_r1 = np.array([0, 60, 60]); upper_r1 = np.array([10, 255, 255])
    lower_r2 = np.array([160, 60, 60]); upper_r2 = np.array([180, 255, 255])
    mask_r = cv2.bitwise_or(cv2.inRange(hsv, lower_r1, upper_r1),
                            cv2.inRange(hsv, lower_r2, upper_r2))
    # è“è‰²
    lower_b = np.array([95, 60, 50]); upper_b = np.array([135, 255, 255])
    mask_b = cv2.inRange(hsv, lower_b, upper_b)

    def detect(mask):
        blur = cv2.GaussianBlur(mask, (5,5), 1.5)
        circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, dp=1.2, minDist=8,
                                   param1=60, param2=10, minRadius=3, maxRadius=20)
        pts = []
        if circles is not None:
            for c in np.uint16(np.around(circles[0])):
                pts.append((int(c[0]), int(c[1])))
        return pts

    red_pts = detect(mask_r)
    blue_pts = detect(mask_b)
    return red_pts, blue_pts

def cluster_columns(points, x_tol=None):
    if not points:
        return []
    pts = sorted(points, key=lambda p: p[0])
    xs = [p[0] for p in pts]
    diffs = [xs[i+1]-xs[i] for i in range(len(xs)-1)] if len(xs)>1 else [16]
    cell_w = int(statistics.median(diffs)) if diffs else 16
    if x_tol is None:
        x_tol = max(8, int(cell_w*0.6))
    cols = [[pts[0]]]
    for p in pts[1:]:
        if abs(p[0] - cols[-1][-1][0]) <= x_tol:
            cols[-1].append(p)
        else:
            cols.append([p])
    return [sorted(c, key=lambda p: p[1]) for c in cols]

def longest_run_in_col(col_pts):
    ys = [p[1] for p in col_pts]
    if not ys: return 0
    runs = 1; best = 1
    for i in range(1, len(ys)):
        if ys[i] - ys[i-1] > 6:
            runs += 1
            best = max(best, runs)
        else:
            # è‹¥å¤ªé è¿‘ï¼Œå¯èƒ½å™ªå£°ï¼Œç»§ç»­è®¡æ•°ä½†ä¸å¢åŠ è¿è¡Œé•¿åº¦
            pass
    return best

def analyze_table_image(img_bgr):
    """
    è¿”å›å•å¼ æ¡Œçš„ç»Ÿè®¡ï¼š
    has_long4, has_long8, has_long10, has_duolian, single_jump_ratio, marker_count
    """
    red_pts, blue_pts = find_red_blue_points(img_bgr)
    marker_count = len(red_pts) + len(blue_pts)

    red_cols = cluster_columns(red_pts)
    blue_cols = cluster_columns(blue_pts)
    all_cols = cluster_columns(red_pts + blue_pts)

    long4_cols_R = [c for c in red_cols if longest_run_in_col(c) >= 4]
    long4_cols_B = [c for c in blue_cols if longest_run_in_col(c) >= 4]

    long8_R = any(longest_run_in_col(c) >= 8 for c in red_cols)
    long8_B = any(longest_run_in_col(c) >= 8 for c in blue_cols)
    long10_R = any(longest_run_in_col(c) >= 10 for c in red_cols)
    long10_B = any(longest_run_in_col(c) >= 10 for c in blue_cols)

    has_long4 = (len(long4_cols_R) + len(long4_cols_B)) > 0
    has_long8 = (long8_R or long8_B)
    has_long10 = (long10_R or long10_B)

    def has_duolian_two(color_cols):
        if len(color_cols) < 2: return False
        cols_with_x = []
        for col in color_cols:
            xs = [p[0] for p in col]
            cols_with_x.append((statistics.mean(xs), col))
        cols_with_x.sort(key=lambda t: t[0])
        for i in range(len(cols_with_x)-1):
            if longest_run_in_col(cols_with_x[i][1]) >= 4 and longest_run_in_col(cols_with_x[i+1][1]) >= 4:
                return True
        return False

    has_duolian = has_duolian_two(long4_cols_R) or has_duolian_two(long4_cols_B)

    if all_cols:
        single_jump_cols = sum(1 for c in all_cols if longest_run_in_col(c) <= 1)
        single_jump_ratio = single_jump_cols / len(all_cols)
    else:
        single_jump_ratio = 1.0

    return {
        "has_long4": has_long4,
        "has_long8": has_long8,
        "has_long10": has_long10,
        "has_duolian": has_duolian,
        "single_jump_ratio": float(single_jump_ratio),
        "marker_count": int(marker_count)
    }

# ========== Playwright: è¿›å…¥ DG å¹¶æˆªå›¾ canvas ==========

def solve_slider_if_any(page):
    # å¸¸è§æ»‘å—å°è¯•ï¼ˆå°½é‡é€šç”¨ï¼‰
    candidates = [
        "div.geetest_slider_button", "div.nc_iconfont.btn_slide", "div.slider",
        "div#nc_1_n1z", "div.yidun_slider", "div.verify-slider", "div.slider-btn",
        "span.btn_slide", "div.slider_button"
    ]
    for sel in candidates:
        try:
            el = page.query_selector(sel)
            if el:
                box = el.bounding_box()
                if box:
                    page.mouse.move(box["x"]+box["width"]/2, box["y"]+box["height"]/2)
                    page.mouse.down()
                    total = 420
                    step = 40
                    for dx in range(0, total, step):
                        page.mouse.move(box["x"]+box["width"]/2+dx, box["y"]+box["height"]/2, steps=2)
                        time.sleep(0.06)
                    page.mouse.up()
                    time.sleep(1.2)
        except Exception:
            continue

def capture_table_canvases(page):
    images = []
    try:
        page.mouse.wheel(0, 300)
        time.sleep(0.3)
    except Exception:
        pass
    canvases = page.query_selector_all("canvas")
    for c in canvases:
        try:
            box = c.bounding_box()
            if not box:
                continue
            if 110 <= box["width"] <= 480 and 70 <= box["height"] <= 320:
                img = c.screenshot()
                images.append(img)
        except Exception:
            continue
    return images

def enter_dg_and_get_tables():
    canvases = []
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True, args=["--disable-blink-features=AutomationControlled"])
            context = browser.new_context(viewport={"width": 1280, "height": 2500})
            page = context.new_page()
            for url in DG_URLS:
                try:
                    page.goto(url, timeout=30000)
                    time.sleep(2.0)
                    # ç‚¹å‡» Free/å…è´¹è¯•ç©
                    for sel in ["text=Free", "text=å…è´¹è¯•ç©", "text=FREE", "text=free"]:
                        try:
                            page.click(sel, timeout=3000)
                            break
                        except Exception:
                            continue
                    # ç­‰å¾…å¯èƒ½å¼¹å‡ºæ–°é¡µ
                    for _ in range(12):
                        time.sleep(0.4)
                        if len(context.pages) > 1:
                            page = context.pages[-1]
                            break
                    solve_slider_if_any(page)
                    time.sleep(1.2)
                    canvases = capture_table_canvases(page)
                    if canvases:
                        browser.close()
                        return canvases
                except Exception:
                    continue
            browser.close()
    except Exception:
        pass
    return canvases

# ========== æ€»ä½“åˆ¤å®šï¼ˆæŒ‰ä½ æ‰€æœ‰é—¨æ§›ï¼‰ ==========

def classify_overall(table_stats):
    n = len(table_stats)
    long4_tables = sum(1 for t in table_stats if t["has_long4"] and t["single_jump_ratio"] < 0.7)
    long8_tables = sum(1 for t in table_stats if t["has_long8"])
    long10_tables = sum(1 for t in table_stats if t["has_long10"])
    duolian_tables = sum(1 for t in table_stats if t["has_duolian"])
    many_single_jump = sum(1 for t in table_stats if t["single_jump_ratio"] >= 0.7)

    long8_only = max(0, long8_tables - long10_tables)
    trigger_super = (long10_tables >= 1 and long8_only >= 2)

    cond_full = False
    if n >= 20 and long4_tables >= 8:
        cond_full = True
    elif n >= 10 and long4_tables >= 4:
        cond_full = True

    cond_mid_up = False
    lng2 = (long8_tables + long10_tables) >= 2
    if ((n >= 20 and long4_tables >= 6) or (n >= 10 and long4_tables >= 3)) and lng2 and duolian_tables >= 1:
        cond_mid_up = True

    cond_harvest = (long8_tables < 2 and many_single_jump >= max(3, int(0.5*n)))

    detail = {
        "tables": n,
        "long4_tables": long4_tables,
        "long8_tables": long8_tables,
        "long10_tables": long10_tables,
        "duolian_tables": duolian_tables,
        "many_single_jump": many_single_jump,
        "trigger_super": trigger_super,
        "cond_full": cond_full,
        "cond_mid_up": cond_mid_up,
        "cond_harvest": cond_harvest
    }

    if trigger_super or cond_full:
        return "FANGSHUI", detail
    if cond_mid_up:
        return "MID_UP", detail
    if cond_harvest:
        return "HARVEST", detail
    return "MID", detail

# ========== çŠ¶æ€æŒä¹…åŒ–ä¸ ETA ä¼°ç®— ==========

def load_state():
    if os.path.exists(STATE_FILE):
        try:
            with open(STATE_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}

def save_state(st):
    try:
        with open(STATE_FILE, "w", encoding="utf-8") as f:
            json.dump(st, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

def estimate_eta(history, threshold_active):
    if len(history) < 3:
        return None, None
    h = history[-6:]
    xs = np.array([(h[i]["ts_ms"] - h[0]["ts_ms"]) / 60000.0 for i in range(len(h))])
    ys = np.array([h[i]["metric"] for i in range(len(h))], dtype=float)
    A = np.vstack([xs, np.ones(len(xs))]).T
    try:
        m, c = np.linalg.lstsq(A, ys, rcond=None)[0]
    except Exception:
        return None, None
    if m >= -1e-6:
        return None, None
    t_cross = (threshold_active - c) / m
    now0 = h[0]["ts_ms"]
    eta_ms = now0 + int(t_cross * 60000)
    mins_left = max(1, int((eta_ms - now_ms()) / 60000))
    eta_dt = datetime.fromtimestamp(eta_ms/1000, TZ)
    return eta_dt, mins_left

# ========== ä¸»æµç¨‹ ==========
def main():
    ts = now_str()
    canvases = enter_dg_and_get_tables()
    detect_ok = len(canvases) > 0
    table_stats = []
    for img_bytes in canvases:
        bgr = bytes_to_bgr(img_bytes)
        stat = analyze_table_image(bgr)
        table_stats.append(stat)

    status, detail = classify_overall(table_stats)

    st = load_state()
    history = st.get("history", [])
    history.append({"ts_ms": now_ms(), "metric": detail.get("long4_tables", 0)})
    history = history[-24:]
    st["history"] = history

    last_status = st.get("status")

    brief = f"æ¡Œæ•°:{detail.get('tables',0)} | é•¿è¿â‰¥4:{detail.get('long4_tables',0)} | é•¿é¾™â‰¥8:{detail.get('long8_tables',0)} | è¶…é•¿é¾™â‰¥10:{detail.get('long10_tables',0)} | å¤šè¿:{detail.get('duolian_tables',0)}"

    msg = None
    if not detect_ok:
        # æ£€æµ‹å¤±è´¥ï¼ˆå¯èƒ½ç½‘é¡µæ— æ³•è®¿é—®æˆ–å…ƒç´ é˜»æŒ¡ï¼‰
        msg = f"âš ï¸ [{ts}] æ£€æµ‹å¤±è´¥ï¼šæ— æ³•æŠ“åˆ°æ¡Œé¢ç”»é¢ï¼Œå¯èƒ½æ˜¯ DG é¡µé¢é˜»æŒ¡æˆ–ç½‘ç»œé—®é¢˜ã€‚è¯·æ£€æŸ¥ã€‚"
    else:
        if status in ("FANGSHUI", "MID_UP"):
            if last_status not in ("FANGSHUI", "MID_UP"):
                st["active_since"] = now_ms()
                st["active_type"] = status
                eta_dt, mins_left = estimate_eta(history, detail.get("long4_tables",0))
                if eta_dt and mins_left:
                    msg = (f"âœ… [{ts}] {'æ”¾æ°´æ—¶æ®µï¼ˆèƒœç‡æé«˜ï¼‰' if status=='FANGSHUI' else 'ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Šï¼‰'} å·²å¼€å§‹\n"
                           f"{brief}\né¢„è®¡ç»“æŸæ—¶é—´ï¼š{eta_dt.strftime('%H:%M')}ï¼ˆé©¬æ¥è¥¿äºšï¼‰\næ­¤å±€åŠ¿é¢„è®¡ï¼šå‰©ä½™çº¦ {mins_left} åˆ†é’Ÿ")
                else:
                    msg = (f"âœ… [{ts}] {'æ”¾æ°´æ—¶æ®µï¼ˆèƒœç‡æé«˜ï¼‰' if status=='FANGSHUI' else 'ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Šï¼‰'} å·²å¼€å§‹\n"
                           f"{brief}\né¢„è®¡ç»“æŸæ—¶é—´ï¼šæš‚æ— æ³•å¯é é¢„ä¼°ï¼ˆè¶‹åŠ¿æœªæ˜¾è‘—ä¸‹é™ï¼‰")
            else:
                # ä»åœ¨æ´»è·ƒï¼Œå‘é€å¿ƒè·³ï¼ˆç®€çŸ­ï¼‰
                msg = f"â„¹ï¸ [{ts}] ä»åœ¨ {'æ”¾æ°´' if status=='FANGSHUI' else 'ä¸­ç­‰èƒœç‡ï¼ˆä¸­ä¸Šï¼‰'} ä¸­ | {brief}"
        else:
            # éæ´»è·ƒï¼ˆMID / HARVESTï¼‰ï¼šå¦‚æœä¹‹å‰æ˜¯æ´»è·ƒä¸”æœ‰ active_since -> å‘ç»“æŸ
            if last_status in ("FANGSHUI", "MID_UP") and st.get("active_since"):
                dur_min = max(1, int((now_ms() - st.get("active_since"))/60000))
                msg = f"ğŸ”” [{ts}] æ”¾æ°´å·²ç»“æŸï¼Œå…±æŒç»­ {dur_min} åˆ†é’Ÿã€‚\n{brief}"
                st["active_since"] = None
                st["active_type"] = None
            else:
                # å¸¸è§„å¿ƒè·³ï¼Œå‘ŠçŸ¥å½“å‰æ— æ”¾æ°´è¿¹è±¡
                msg = f"â„¹ï¸ [{ts}] æ£€æµ‹å®Œæˆï¼šç›®å‰æ— æ”¾æ°´è¿¹è±¡ã€‚{brief}"

    st["status"] = status
    save_state(st)

    if msg:
        send_telegram(msg)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        err = f"è¿è¡Œå¼‚å¸¸ï¼š{e}\\n{traceback.format_exc()}"
        try:
            send_telegram("âš ï¸ DG Monitor è¿è¡Œå¼‚å¸¸ï¼š\\n" + (err[:3000]))
        except Exception:
            pass
        with open("last_error.txt", "w", encoding="utf-8") as f:
            f.write(err)
PY

      - name: Run monitor.py
        env:
          # å¯åœ¨ä»“åº“ Settings->Secrets->Actions è®¾ç½® TG_TOKEN / TG_CHAT_ID è¦†ç›–
          TG_TOKEN: ${{ secrets.TG_TOKEN }}
          TG_CHAT_ID: ${{ secrets.TG_CHAT_ID }}
        run: |
          python monitor.py

      - name: Persist state (commit state file)
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git add -A
            git commit -m "auto: update state [skip ci]" || true
            git push || true
          fi
